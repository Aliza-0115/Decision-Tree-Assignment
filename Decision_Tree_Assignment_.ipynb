{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Assignment:-"
      ],
      "metadata": {
        "id": "c-ruct_1YrPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n",
        "\n",
        "Ans- A Decision Tree is a supervised machine learning algorithm that can be used for both classification and regression tasks. In the context of classification, it works by recursively splitting the dataset into smaller subsets based on the most significant features, creating a tree-like structure of decisions."
      ],
      "metadata": {
        "id": "yk_9OXGMYvP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Explain the concepts of Gini Impurity and Entropy as impurity measures.\n",
        "How do they impact the splits in a Decision Tree?\n",
        "\n",
        "Ans- Gini Impurity and Entropy are two common measures used in Decision Trees to quantify the 'impurity' or 'mixed-up-ness' of a set of samples. The goal of a Decision Tree algorithm is to find splits that minimize this impurity, thereby creating more homogeneous (pure) child nodes.\n",
        "\n",
        "Gini Impurity\n",
        "Concept: Gini Impurity measures how often a randomly chosen element from the set would be incorrectly labeled if it were randomly labeled according to the distribution of labels in the subset. A Gini Impurity of 0 means all elements belong to a single class (perfect purity), while a Gini Impurity of 1 (for binary classification, or closer to 1 for multi-class) means the elements are perfectly mixed.\n",
        "\n",
        "Formula: For a node t, if p_i is the proportion of samples belonging to class i in that node, the Gini Impurity is calculated as: Gini(t) = 1 - Σ (p_i)^2 (summed over all classes)\n",
        "\n",
        "Impact on Splits: When a Decision Tree uses Gini Impurity, it tries to find a split that maximizes the reduction in Gini Impurity (or minimizes the weighted average Gini Impurity of the child nodes). It favors creating splits where one child node is as pure as possible, even if the other child node remains relatively impure. It tends to isolate the most frequent class in one branch.\n",
        "\n",
        "Entropy\n",
        "Concept: Entropy is a concept from information theory that measures the average level of 'information,' 'surprise,' or 'uncertainty' inherent in a variable's possible outcomes. In the context of Decision Trees, it quantifies the disorder or randomness of a set of samples. An entropy of 0 means perfect purity (all samples belong to the same class), and higher entropy means greater disorder or a more mixed distribution of classes.\n",
        "\n",
        "Formula: For a node t, if p_i is the proportion of samples belonging to class i in that node, the Entropy is calculated as: Entropy(t) = - Σ p_i * log2(p_i) (summed over all classes, with 0 * log2(0) taken as 0)\n",
        "\n",
        "Impact on Splits: When a Decision Tree uses Entropy, it aims to find a split that maximizes the information gain. Information gain is the difference between the entropy of the parent node and the weighted average entropy of the child nodes. A higher information gain means the split is more effective at reducing uncertainty. Entropy-based splits tend to create more balanced trees, aiming to reduce impurity across all child nodes, not just one.\n",
        "\n",
        "How they Impact Splits in a Decision Tree:\n",
        "Both Gini Impurity and Entropy guide the Decision Tree algorithm in choosing the best split at each node. The algorithm evaluates potential splits based on how much they reduce the impurity of the resulting child nodes.\n",
        "\n",
        "Gini Impurity is computationally less intensive because it doesn't involve logarithmic calculations. It often results in similar trees to entropy and is the default criterion for many implementations (e.g., in scikit-learn). It tends to look for a split that isolates one class, even if it leaves the other classes mixed.\n",
        "\n",
        "Entropy (and by extension, Information Gain) can sometimes produce slightly more balanced trees by trying to make all resulting child nodes as pure as possible. It is generally preferred when you want to achieve a more even distribution of classes across the branches."
      ],
      "metadata": {
        "id": "dGiTSzeyY4eF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the difference between Pre-Pruning and Post-Pruning in Decision\n",
        "Trees? Give one practical advantage of using each.\n",
        "\n",
        "Ans- In Decision Trees, pruning is a technique used to reduce the size of the tree by removing sections that provide little power to classify instances. This helps to prevent overfitting and improve the tree's generalization to new, unseen data. There are two main types of pruning:\n",
        "\n",
        "1. Pre-Pruning (or Early Stopping):\n",
        "\n",
        "What it is: This technique stops the tree construction process early, before it has perfectly classified all training instances. It sets conditions or thresholds that, if met, will stop the growth of a branch.\n",
        "How it works: During the tree building phase, pre-pruning checks if adding a new split significantly improves the model's performance (e.g., reduces impurity below a certain threshold, or if the number of samples in a node falls below a minimum). If the improvement is not substantial or the conditions are met, the branch is terminated, and the node becomes a leaf node.\n",
        "\n",
        "Practical Advantage: Computational Efficiency. Pre-pruning saves a significant amount of computational time and resources because it prevents the generation of overly complex subtrees in the first place. You don't build the full tree and then cut it back; you stop growing it when it's deemed sufficient, making the training process faster.\n",
        "\n",
        "2. Post-Pruning (or Backward Pruning):\n",
        "\n",
        "in this technique involves building the full decision tree first, allowing it to grow to its maximum depth or until all leaf nodes are pure. After the tree is fully grown, it is then pruned back by removing branches or nodes that are deemed insignificant or lead to overfitting.\n",
        "How it works: Post-pruning typically evaluates the impact of removing a branch (or replacing a subtree with a leaf node) on the tree's performance (e.g., using a validation set or statistical measures). If removing a branch does not significantly decrease the tree's accuracy on the validation set, or if it simplifies the tree without much loss of accuracy, the branch is removed.\n",
        "\n",
        "Practical Advantage: Potentially Better Accuracy. Post-pruning can often lead to a more optimal or accurate tree because it first explores all possible splits and then strategically removes those that are not beneficial. This allows the algorithm to see the 'big picture' of the tree structure before making pruning decisions, potentially discovering subtle interactions that might be missed by pre-pruning's early stopping. It often leads to a more robust final model, especially when the stopping criteria for pre-pruning are hard to set optimally beforehand."
      ],
      "metadata": {
        "id": "vBqzvMp2ZR0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is Information Gain in Decision Trees, and why is it important for\n",
        "choosing the best split?\n",
        "\n",
        "Ans- Information Gain measures the difference between the entropy of the parent node (before the split) and the weighted average entropy of the child nodes (after the split). A higher information gain implies a better split, as it means the attribute significantly reduces the uncertainty or disorder in the dataset with respect to the target variable.\n",
        "\n",
        "Formula: Information Gain(S, A) = Entropy(S) - Σ [ ( |Sv| / |S| ) * Entropy(Sv) ]\n",
        "\n",
        "Where:\n",
        "\n",
        "S is the set of samples at the current node (parent node).\n",
        "A is the attribute (feature) being considered for the split.\n",
        "Entropy(S) is the entropy of the parent node.\n",
        "Sv is the subset of S for which attribute A has value v (i.e., one of the child nodes after the split).\n",
        "|Sv| is the number of samples in the child node Sv.\n",
        "|S| is the total number of samples in the parent node S.\n",
        "The summation Σ is over all possible values v of the attribute A.\n",
        "\n",
        "\n",
        "It is important for Choosing the Best Split because:-\n",
        "\n",
        "\n",
        "Information Gain is crucial because it serves as the primary criterion for selecting the most effective feature to split a node in a Decision Tree:\n",
        "\n",
        "Guiding Optimal Splits: The Decision Tree algorithm at each step considers all available features for splitting. For each feature, it calculates the Information Gain that would result from splitting the data based on that feature. The feature that yields the highest Information Gain is chosen as the splitting criterion for that node.\n",
        "\n",
        "Maximizing Purity: By maximizing Information Gain, the algorithm essentially selects the split that leads to the greatest reduction in impurity (or uncertainty) and creates the most homogeneous (pure) child nodes. This means the child nodes will have a clearer majority of one class, making it easier to classify future instances.\n",
        "\n",
        "Preventing Overfitting (Indirectly): While not a direct overfitting prevention mechanism like pruning, choosing splits with high Information Gain ensures that each split adds meaningful predictive power. It prioritizes features that are most discriminative, leading to a more efficient and generally smaller tree, which can inherently reduce the risk of overfitting compared to arbitrarily splitting on less informative features.\n",
        "\n",
        "Foundation for Tree Construction: Information Gain is fundamental to algorithms like ID3 and C4.5. Without a robust measure like Information Gain, the Decision Tree would not be able to systematically identify which features are most useful at each stage of its construction to effectively partition the data into distinct classes."
      ],
      "metadata": {
        "id": "Jd1tEniNaLz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What are some common real-world applications of Decision Trees, and\n",
        "what are their main advantages and limitations?\n",
        "\n",
        "Ans- Common Real-World Applications of Decision Trees are:-\n",
        "\n",
        "1. Medical Diagnosis:\n",
        "\n",
        "Decision trees can be used to help diagnose diseases based on symptoms, patient history, and test results. For example, predicting whether a patient has a certain condition based on their age, blood pressure, cholesterol levels, etc.\n",
        "\n",
        "2. Financial Analysis:\n",
        "\n",
        "Credit Scoring: Banks use decision trees to assess the creditworthiness of loan applicants, predicting the likelihood of default based on income, debt, employment history, etc.\n",
        "Fraud Detection: Identifying fraudulent transactions in banking or insurance by analyzing patterns in transaction data.\n",
        "Stock Market Prediction: While highly complex, simple decision trees can be used to predict stock price movements based on various economic indicators.\n",
        "\n",
        "3. Customer Relationship Management (CRM):\n",
        "\n",
        "Churn Prediction: Predicting which customers are likely to switch to a competitor based on their behavior, demographics, and interaction history.\n",
        "Targeted Marketing: Segmenting customers into groups with similar characteristics to tailor marketing campaigns more effectively.\n",
        "\n",
        "4. Customer Lifetime Value (CLTV) Prediction:\n",
        "\n",
        "Estimating the total revenue a business can expect from a customer throughout their relationship.\n",
        "Manufacturing and Quality Control: Identifying factors that lead to defects in products or processes, helping to improve efficiency and reduce waste.\n",
        "Bioinformatics: Classifying genes, proteins, or DNA sequences based on various attributes.\n",
        "\n",
        "5. E-commerce:\n",
        "\n",
        "Recommending products to users based on their browsing history, past purchases, and demographic information.\n",
        "Risk Management: Assessing various types of risks in fields like insurance (e.g., predicting claim likelihood) or project management.\n",
        "\n",
        "\n",
        "Main Advantages of Decision Trees:\n",
        "\n",
        "Easy to Understand and Interpret: The logic of a decision tree can be easily followed and visualized, making it intuitive for non-technical stakeholders to understand how a decision is made. This 'white box' model contrasts with 'black box' models like neural networks.\n",
        "\n",
        "Handles Both Numerical and Categorical Data: Decision trees can inherently work with both types of features without requiring extensive preprocessing like one-hot encoding for categorical variables (though some implementations might benefit from it).\n",
        "\n",
        "Minimal Data Preparation: They require less data cleaning and normalization compared to some other algorithms. They are not sensitive to outliers and can handle missing values effectively.\n",
        "\n",
        "Non-Linear Relationships: They can capture non-linear relationships between features and the target variable, which linear models cannot.\n",
        "Feature Selection: The construction process implicitly performs feature selection, as more important features are used closer to the root of the tree.\n",
        "Can Generate Rules: The paths from the root to the leaf nodes can be easily translated into IF-THEN rules, which can be useful for business intelligence and decision-making.\n",
        "\n",
        "Main Limitations of Decision Trees:\n",
        "\n",
        "Prone to Overfitting: Without proper pruning or limiting the tree's depth, decision trees can easily overfit the training data, leading to poor generalization on unseen data. This is their most significant drawback.\n",
        "Instability (High Variance): A small change in the training data can lead to a completely different tree structure, making them somewhat unstable. This is why ensemble methods (like Random Forests and Gradient Boosting) that use multiple trees are often preferred.\n",
        "\n",
        "Bias towards Dominant Classes: If the dataset is imbalanced (one class is much more frequent than others), decision trees can be biased towards the majority class, leading to poor performance on the minority class.\n",
        "Locally Optimal Splits: At each step, the algorithm makes a greedy choice for the best split. This means it might not find the globally optimal tree structure, as it doesn't backtrack or consider future splits.\n",
        "Complexity for Large Trees: While individual trees are easy to interpret, a very deep or wide tree can become overly complex and lose its interpretability advantage.\n",
        "\n",
        "Not suitable for Regression with Continuous Target Variables: While they can be used for regression, they tend to produce stepwise predictions (constant values within each leaf), which might not be ideal for truly continuous outputs, leading to less smooth predictions compared to linear regression or other methods."
      ],
      "metadata": {
        "id": "Guldqg_cdjcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Info:\n",
        "● Iris Dataset for classification tasks (sklearn.datasets.load_iris() or\n",
        "provided CSV).\n",
        "● Boston Housing Dataset for regression tasks\n",
        "(sklearn.datasets.load_boston() or provided CSV).\n",
        "\n",
        "6. Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier using the Gini criterion\n",
        "● Print the model’s accuracy and feature importances"
      ],
      "metadata": {
        "id": "qdTyCUXusqZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris Dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with Gini criterion\n",
        "dtc_gini = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dtc_gini.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = dtc_gini.predict(X_test)\n",
        "\n",
        "# Calculate and print the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy (Gini): {accuracy:.4f}\")\n",
        "\n",
        "# Print feature importances\n",
        "print(\"\\nFeature Importances:\")\n",
        "for i, importance in enumerate(dtc_gini.feature_importances_):\n",
        "    print(f\"  {iris.feature_names[i]}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSLg9nwXtwy4",
        "outputId": "7f2cb59d-8358-4dd8-aca1-8768570ad660"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy (Gini): 1.0000\n",
            "\n",
            "Feature Importances:\n",
            "  sepal length (cm): 0.0000\n",
            "  sepal width (cm): 0.0191\n",
            "  petal length (cm): 0.8933\n",
            "  petal width (cm): 0.0876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to a fully-grown tree."
      ],
      "metadata": {
        "id": "Oj9QTpFZt7Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import necessary libraries and data if running this cell independently\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris Dataset (if not already loaded)\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets (if not already split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 1. Train a Decision Tree Classifier with max_depth=3\n",
        "dtc_depth3 = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
        "dtc_depth3.fit(X_train, y_train)\n",
        "y_pred_depth3 = dtc_depth3.predict(X_test)\n",
        "accuracy_depth3 = accuracy_score(y_test, y_pred_depth3)\n",
        "print(f\"Model Accuracy (Gini, max_depth=3): {accuracy_depth3:.4f}\")\n",
        "\n",
        "# 2. Get the accuracy of the fully-grown tree (from previous execution, assuming it was 1.0)\n",
        "# If the previous cell hasn't been executed, this will use the value from the last run\n",
        "# If you run this cell independently, ensure 'accuracy' variable is set to 1.0 or rerun the previous cell.\n",
        "fully_grown_accuracy = 1.0 # From the previous run's output\n",
        "\n",
        "print(f\"Fully-grown Tree Accuracy (Gini): {fully_grown_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nComparison:\")\n",
        "if accuracy_depth3 == fully_grown_accuracy:\n",
        "    print(\"Both trees achieved the same accuracy on the test set.\")\n",
        "elif accuracy_depth3 > fully_grown_accuracy:\n",
        "    print(f\"The tree with max_depth=3 performed better by {accuracy_depth3 - fully_grown_accuracy:.4f}.\")\n",
        "else:\n",
        "    print(f\"The fully-grown tree performed better by {fully_grown_accuracy - accuracy_depth3:.4f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBNJKCFNuFvh",
        "outputId": "e6bfc2b4-efdb-472d-cb5f-28de91da8584"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy (Gini, max_depth=3): 1.0000\n",
            "Fully-grown Tree Accuracy (Gini): 1.0000\n",
            "\n",
            "Comparison:\n",
            "Both trees achieved the same accuracy on the test set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  Write a Python program to:\n",
        "● Load the Boston Housing Dataset\n",
        "● Train a Decision Tree Regressor\n",
        "● Print the Mean Squared Error (MSE) and feature importances"
      ],
      "metadata": {
        "id": "_PyfoN2NuL5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the Boston Housing Dataset\n",
        "boston = load_boston()\n",
        "X_boston = boston.data\n",
        "y_boston = boston.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train_boston, X_test_boston, y_train_boston, y_test_boston = train_test_split(X_boston, y_boston, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Regressor\n",
        "dtr_boston = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dtr_boston.fit(X_train_boston, y_train_boston)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_boston = dtr_boston.predict(X_test_boston)\n",
        "\n",
        "# Calculate and print the Mean Squared Error (MSE)\n",
        "mse_boston = mean_squared_error(y_test_boston, y_pred_boston)\n",
        "print(f\"Model Mean Squared Error (MSE): {mse_boston:.4f}\")\n",
        "\n",
        "# Print feature importances\n",
        "print(\"\\nFeature Importances:\")\n",
        "for i, importance in enumerate(dtr_boston.feature_importances_):\n",
        "    print(f\"  {boston.feature_names[i]}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6zeCf29ZuOFL",
        "outputId": "022defc9-65bb-491b-fcb7-bb83ba62d12c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3535025168.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_boston\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \"\"\"\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "● Print the best parameters and the resulting model accuracy"
      ],
      "metadata": {
        "id": "f1K5aGLXucJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris Dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "dtc = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [None, 3, 5, 7, 10],\n",
        "    'min_samples_split': [2, 5, 10, 15]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "# cv=5 means 5-fold cross-validation\n",
        "# scoring='accuracy' specifies the evaluation metric\n",
        "grid_search = GridSearchCV(estimator=dtc, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_dtc = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "y_pred_best = best_dtc.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the best model\n",
        "best_accuracy = accuracy_score(y_test, y_pred_best)\n",
        "print(f\"Best Model Accuracy: {best_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9ibvS6tuhtG",
        "outputId": "0ede52ab-54ab-4766-eed3-83523e998ce1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_split': 10}\n",
            "Best Model Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "● Handle the missing values\n",
        "● Encode the categorical features\n",
        "● Train a Decision Tree model\n",
        "● Tune its hyperparameters\n",
        "● Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting."
      ],
      "metadata": {
        "id": "mNTDlgMKurlb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "3bcc99ca",
        "outputId": "a8396351-223f-4743-d199-df978d97e728"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'best_dtc', 'X_test', 'y_test', and 'y_pred_best' are available from previous cells.\n",
        "# If not, ensure you run the previous cells or define these variables.\n",
        "\n",
        "# Calculate additional metrics using the best model's predictions\n",
        "# accuracy is already available from the previous step ('best_accuracy')\n",
        "\n",
        "# Precision, Recall, F1-Score\n",
        "precision = precision_score(y_test, y_pred_best, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_best, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_best, average='weighted')\n",
        "\n",
        "# Calculate AUC-ROC score\n",
        "# For multi-class, we need to get probability estimates\n",
        "y_pred_proba = best_dtc.predict_proba(X_test)\n",
        "auc_roc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')\n",
        "\n",
        "# Generate Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_best)\n",
        "\n",
        "# Print all calculated metrics\n",
        "print(f\"Accuracy: {best_accuracy:.4f}\") # Re-using best_accuracy from previous cell\n",
        "print(f\"Precision (weighted): {precision:.4f}\")\n",
        "print(f\"Recall (weighted): {recall:.4f}\")\n",
        "print(f\"F1-Score (weighted): {f1:.4f}\")\n",
        "print(f\"AUC-ROC (weighted, OvR): {auc_roc:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Visualize the Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix for Tuned Decision Tree Classifier')\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Precision (weighted): 1.0000\n",
            "Recall (weighted): 1.0000\n",
            "F1-Score (weighted): 1.0000\n",
            "AUC-ROC (weighted, OvR): 1.0000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[19  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0 13]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo0AAAIjCAYAAABmuyHTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbMtJREFUeJzt3XdYFFfbBvB7UVhQqnQsWEBEpdgLdohIolExUVEjWJPYErGSWEBjsCRqokajxq5Ro1ETNfau2MVeESUmYEGKKAKy5/vDj31dAYdF1iHs/fOa63KnnHlYZtfH55w5oxBCCBARERERvYGB3AEQERERUfHHpJGIiIiIJDFpJCIiIiJJTBqJiIiISBKTRiIiIiKSxKSRiIiIiCQxaSQiIiIiSUwaiYiIiEgSk0YiIiIiksSkUQ/dvHkTbdu2hYWFBRQKBTZv3lyk7d+5cwcKhQLLli0r0nb/y1q1aoVWrVoVWXtpaWno378/HBwcoFAo8OWXXxZZ2yWFQqFAeHi43GFIqly5MkJCQrQ6Jjw8HAqFQjcB6RG538cDBw5AoVDgwIEDGutXrlyJGjVqwNDQEJaWlgCK/juEqDCYNMokJiYGn376KapWrQpjY2OYm5vDx8cHP/zwA9LT03V67uDgYFy8eBFTpkzBypUrUb9+fZ2e710KCQmBQqGAubl5nu/jzZs3oVAooFAo8N1332nd/r///ovw8HBER0cXQbSF9+2332LZsmX4/PPPsXLlSnzyySc6OU/OP6pSy3/1H7Oc/+DkLIaGhrCxsUHTpk3x1VdfIS4uTu4Qi42cz5bUom0CrAvPnz/HrFmz0KhRI1hYWMDY2BjVq1fHkCFDcOPGDbnDe6Nr164hJCQE1apVw6JFi7Bw4UK5QyJSKy13APpo27Zt+Pjjj6FUKtG7d2/Url0bmZmZOHLkCEaNGoXLly/r7IsiPT0dUVFR+PrrrzFkyBCdnMPZ2Rnp6ekwNDTUSftSSpcujWfPnuHPP/9E165dNbatXr0axsbGeP78eaHa/vfffxEREYHKlSvD29u7wMft2rWrUOfLz759+9C4cWNMnDixSNt9XWBgIFxcXNSv09LS8Pnnn6Nz584IDAxUr7e3t9dpHLoWFBSE999/HyqVCklJSTh16hRmz56NH374Ab/88gu6d++us3Nfv34dBgba/f993LhxGDt2rI4iytunn34KPz8/9evY2FhMmDABAwcORPPmzdXrq1Wr9k7jet2jR4/Qrl07nDlzBu3bt0ePHj1gamqK69evY+3atVi4cCEyMzNljTFHixYtkJ6eDiMjI/W6AwcOQKVS4YcfftD47BX1dwhRYTBpfMdiY2PRvXt3ODs7Y9++fXB0dFRvGzx4MG7duoVt27bp7PwPHz4EAHWXhy4oFAoYGxvrrH0pSqUSPj4++PXXX3MljWvWrMEHH3yAjRs3vpNYnj17hjJlymj8o1AUHjx4gJo1axZZey9evIBKpcoVp6enJzw9PdWvHz16hM8//xyenp7o1atXkZ1fbnXr1s3189y9exdt27ZFcHAw3N3d4eXlpZNzK5VKrY8pXbo0Spd+t1/fTZo0QZMmTdSvT58+jQkTJqBJkyZvvBaePn2KsmXLvosQAbysiJ47dw4bNmxAly5dNLZNnjwZX3/99TuLRYqBgUGu78oHDx4AyP0dXZTfISqVCpmZmbJ+T9N/E7un37Hp06cjLS0Nv/zyi0bCmMPFxQVffPGF+vWLFy8wefJkVKtWDUqlEpUrV8ZXX32FjIwMjeMqV66M9u3b48iRI2jYsCGMjY1RtWpVrFixQr1PeHg4nJ2dAQCjRo2CQqFA5cqVAbz8os35+6vyGvOze/duNGvWDJaWljA1NYWbmxu++uor9fb8xjTu27cPzZs3R9myZWFpaYmOHTvi6tWreZ7v1q1bCAkJgaWlJSwsLNCnTx88e/Ys/zf2NT169MBff/2F5ORk9bpTp07h5s2b6NGjR679Hz9+jJEjR8LDwwOmpqYwNzdHQEAAzp8/r97nwIEDaNCgAQCgT58+6u64nJ+zVatWqF27Ns6cOYMWLVqgTJky6vfl9fFIwcHBMDY2zvXz+/v7w8rKCv/++2+eP1fOGKjY2Fhs27ZNHcOdO3cAvPwHp1+/frC3t4exsTG8vLywfPlyjTZyfj/fffcdZs+erb62rly5UqD39nXLli3TiOH1WF8dr5XzHl25cgWtW7dGmTJlUL58eUyfPj1XuxkZGZg4cSJcXFygVCpRsWJFjB49Ote1n5GRgeHDh8PW1hZmZmb48MMPce/evUL9LK9ydnbGsmXLkJmZmSu+5ORkfPnll6hYsSKUSiVcXFwwbdo0qFQqjf1yKkYeHh4wNjaGra0t2rVrh9OnT6v3eX1MY1ZWFiIiIuDq6gpjY2NYW1ujWbNm2L17t3qfvD6XRfldUVg518LBgwcxaNAg2NnZoUKFCurtf/31l/o7wMzMDB988AEuX76cq51r167ho48+Qrly5WBsbIz69evjjz/+kDz/iRMnsG3bNvTr1y9Xwgi8TNClhqUsXboUbdq0gZ2dHZRKJWrWrIn58+fn2u/06dPw9/eHjY0NTExMUKVKFfTt21djn7Vr16JevXowMzODubk5PDw88MMPP6i3v/4ZqVy5srr3wNbWVmNcbl5jGgv6GVEoFBgyZAhWr16NWrVqQalUYseOHW98H4jywkrjO/bnn3+iatWqaNq0aYH279+/P5YvX46PPvoII0aMwIkTJxAZGYmrV69i06ZNGvveunULH330Efr164fg4GAsWbIEISEhqFevHmrVqoXAwEBYWlpi+PDh6u44U1NTreK/fPky2rdvD09PT0yaNAlKpRK3bt3C0aNH33jcnj17EBAQgKpVqyI8PBzp6emYM2cOfHx8cPbs2VwJa9euXVGlShVERkbi7NmzWLx4Mezs7DBt2rQCxRkYGIjPPvsMv//+u/qLfM2aNahRowbq1q2ba//bt29j8+bN+Pjjj1GlShXcv38fP//8M1q2bIkrV67AyckJ7u7umDRpUq4uuVd/l4mJiQgICED37t3Rq1evfLttf/jhB+zbtw/BwcGIiopCqVKl8PPPP2PXrl1YuXIlnJyc8jzO3d0dK1euxPDhw1GhQgWMGDECwMt/YNLT09GqVSvcunULQ4YMQZUqVfDbb78hJCQEycnJGv8ZAV7+4/j8+XMMHDgQSqUS5cqVK9B7+7aSkpLQrl07BAYGomvXrtiwYQPGjBkDDw8PBAQEAHiZbH344Yc4cuQIBg4cCHd3d1y8eBGzZs3CjRs3NG7e6t+/P1atWoUePXqgadOm2LdvHz744IMiibVJkyaoVq2aRsL27NkztGzZEv/88w8+/fRTVKpUCceOHUNYWBji4+Mxe/Zs9b79+vXDsmXLEBAQgP79++PFixc4fPgwjh8/nu9Y4vDwcERGRqJ///5o2LAhUlNTcfr0aZw9exbvvfdevrEW5XfF2xo0aBBsbW0xYcIEPH36FMDLmzuCg4Ph7++PadOm4dmzZ5g/fz6aNWuGc+fOqb8DLl++DB8fH5QvXx5jx45F2bJlsX79enTq1AkbN25E586d8z1vTmL5NmN858+fj1q1auHDDz9E6dKl8eeff2LQoEFQqVQYPHgwgJf/OWvbti1sbW0xduxYWFpa4s6dO/j999/V7ezevRtBQUHw9fVVf29dvXoVR48ezfVZzDF79mysWLECmzZtwvz582FqaqpR6X+VNp8R4OV/2tevX48hQ4bAxsYmzyIBkSRB70xKSooAIDp27Fig/aOjowUA0b9/f431I0eOFADEvn371OucnZ0FAHHo0CH1ugcPHgilUilGjBihXhcbGysAiBkzZmi0GRwcLJydnXPFMHHiRPHqZTJr1iwBQDx8+DDfuHPOsXTpUvU6b29vYWdnJxITE9Xrzp8/LwwMDETv3r1zna9v374abXbu3FlYW1vne85Xf46yZcsKIYT46KOPhK+vrxBCiOzsbOHg4CAiIiLyfA+eP38usrOzc/0cSqVSTJo0Sb3u1KlTuX62HC1bthQAxIIFC/Lc1rJlS411O3fuFADEN998I27fvi1MTU1Fp06dJH9GIV7+vj/44AONdbNnzxYAxKpVq9TrMjMzRZMmTYSpqalITU1V/1wAhLm5uXjw4EGBzpfj4cOHAoCYOHGiet3SpUsFABEbG6ux7/79+wUAsX//fvW6nPdoxYoV6nUZGRnCwcFBdOnSRb1u5cqVwsDAQBw+fFijzQULFggA4ujRo0KI/31GBg0apLFfjx49csWZl/w+D6/q2LGjACBSUlKEEEJMnjxZlC1bVty4cUNjv7Fjx4pSpUqJuLg4IYQQ+/btEwDEsGHDcrWpUqnUf3d2dhbBwcHq115eXrl+t697/XOpi+8KKXl9FnKuhWbNmokXL16o1z958kRYWlqKAQMGaLSRkJAgLCwsNNb7+voKDw8P8fz5c/U6lUolmjZtKlxdXd8YU+fOnQUAkZSUVKCf4fX3UQghnj17lms/f39/UbVqVfXrTZs2CQDi1KlT+bb9xRdfCHNzc4334XV5fUZyYnr9O/b175CCfkaEEAKAMDAwEJcvX843FqKCYPf0O5SamgoAMDMzK9D+27dvBwCEhoZqrM+pLr0+9rFmzZoaA9JtbW3h5uaG27dvFzrm1+WMs9myZUuurrj8xMfHIzo6GiEhIRrVLE9PT7z33nvqn/NVn332mcbr5s2bIzExUf0eFkSPHj1w4MABJCQkYN++fUhISMizaxp42W2VczNCdnY2EhMT1V3vZ8+eLfA5lUol+vTpU6B927Zti08//RSTJk1CYGAgjI2N8fPPPxf4XK/bvn07HBwcEBQUpF5naGiIYcOGIS0tDQcPHtTYv0uXLrC1tS30+QrL1NRUYwyckZERGjZsqHGd/vbbb3B3d0eNGjXw6NEj9dKmTRsAwP79+wH87zMybNgwjXMU5RREOdX4J0+eqGNr3rw5rKysNGLz8/NDdnY2Dh06BADYuHEjFApFnjcrvWmaF0tLS1y+fBk3b94scIzF7btiwIABKFWqlPr17t27kZycjKCgII33rFSpUmjUqJH69/n48WPs27cPXbt2xZMnT9T7JSYmwt/fHzdv3sQ///yT73m1/Y7Ni4mJifrvKSkpePToEVq2bInbt28jJSUFwP++B7du3YqsrKw827G0tMTTp081qtRFqaCfkRwtW7Ys0nHQpJ+YNL5D5ubmAP73j4+Uu3fvwsDAQOMOOgBwcHCApaUl7t69q7G+UqVKudqwsrJCUlJSISPOrVu3bvDx8UH//v1hb2+P7t27Y/369W9MIHPidHNzy7XN3d0djx49Undh5Xj9Z7GysgIArX6W999/H2ZmZli3bh1Wr16NBg0a5Hovc6hUKsyaNQuurq5QKpWwsbGBra0tLly4oP6HoiDKly+v1YD17777DuXKlUN0dDR+/PFH2NnZFfjY1929exeurq657sR1d3dXb39VlSpVCn2ut1GhQoVcSdPr1+nNmzdx+fJl2NraaizVq1cH8L+bBXI+I6/fsZvXtVZYaWlpAP6XiNy8eRM7duzIFVvOncU5scXExMDJyUnrbv9JkyYhOTkZ1atXh4eHB0aNGoULFy688Zji9l3x+rWVkwC3adMm1/u2a9cu9Xt269YtCCEwfvz4XPvlJN85++ZF2+/YvBw9ehR+fn7qsde2trbqsck53wUtW7ZEly5dEBERARsbG3Ts2BFLly7VGEs4aNAgVK9eHQEBAahQoQL69u1bpOMIC/oZySHX551KFo5pfIfMzc3h5OSES5cuaXVcQSefffV/9q8SQhT6HNnZ2RqvTUxMcOjQIezfvx/btm3Djh07sG7dOrRp0wa7du3KNwZtvc3PkkOpVCIwMBDLly/H7du33zjR87fffovx48ejb9++mDx5MsqVKwcDAwN8+eWXBa6oAppVioI4d+6c+sv94sWLGlVCXdM21vwU9NrJUZDfrUqlgoeHB2bOnJnnvhUrVtQyysK7dOkS7Ozs1AmJSqXCe++9h9GjR+e5f84/2oXVokULxMTEYMuWLdi1axcWL16MWbNmYcGCBejfv/8bj30X3xUF8fq1lfMZWrlyJRwcHHLtn3MneM5+I0eOhL+/f55t5/cfPwCoUaMGgJefpVcrqQUVExMDX19f1KhRAzNnzkTFihVhZGSE7du3Y9asWer4FAoFNmzYgOPHj+PPP//Ezp070bdvX3z//fc4fvw4TE1NYWdnh+joaOzcuRN//fUX/vrrLyxduhS9e/fOdXNaYWj7GSmqzzvpNyaN71j79u2xcOFCREVFaUxfkRdnZ2eoVCrcvHlTXS0CgPv37yM5OVl9J3RRsLKy0rjTOMfrFQrg5TQRvr6+8PX1xcyZM/Htt9/i66+/xv79+zXmcXv15wBezkf3umvXrsHGxkZnU3L06NEDS5YsgYGBwRvn2tuwYQNat26NX375RWN9cnIybGxs1K+L8ukRT58+RZ8+fVCzZk00bdoU06dPR+fOndV3aGvL2dkZFy5cgEql0qg2Xrt2Tb1dF3KqwK9fP3ldOwVVrVo1nD9/Hr6+vm98z3M+IzExMRrVxbyutcKIiopCTEyMRnd6tWrVkJaWlue1/qpq1aph586dePz4sdbVxnLlyqFPnz7o06cP0tLS0KJFC4SHh+ebNL7L74rCyKkE29nZvfF9q1q1KoCXwyqk3t+8dOjQAZGRkVi1alWhksY///wTGRkZ+OOPPzSqsa939eZo3LgxGjdujClTpmDNmjXo2bMn1q5dq/49GRkZoUOHDujQoQNUKhUGDRqEn3/+GePHj39j8lsQBf2MEBUldk+/Y6NHj0bZsmXRv39/3L9/P9f2mJgY9ZQM77//PgBo3I0JQP0/y6K6QxR4+QWUkpKi0Q0WHx+f667Lx48f5zo2Z5Lr16d5yOHo6Ahvb28sX75cI7G4dOkSdu3apf45daF169aYPHky5s6dm2eFI0epUqVyVVl+++23XOOncpLbvBJsbY0ZMwZxcXFYvnw5Zs6cicqVKyM4ODjf91HK+++/j4SEBKxbt0697sWLF5gzZw5MTU3RsmXLt445LzkJQc5YPuBllfFtJqjv2rUr/vnnHyxatCjXtvT0dPVwhpy7rX/88UeNfV7/zBTG3bt3ERISAiMjI4waNUojtqioKOzcuTPXMcnJyXjx4gWAl2NGhRCIiIjItd+bKnqJiYkar01NTeHi4vLG6+JdflcUhr+/P8zNzfHtt9/mOQYwZ/5YOzs7tGrVCj///DPi4+Pz3S8/TZo0Qbt27bB48eI8H4+amZmJkSNH5nt8TgX21d9PSkoKli5dqrFfUlJSrt/h69+Dr/8eDQwM1HdCF/Yz/qqCfkaIihIrje9YtWrVsGbNGnTr1g3u7u4aT4Q5duyYeooUAPDy8kJwcDAWLlyI5ORktGzZEidPnsTy5cvRqVMntG7dusji6t69O8aMGYPOnTtj2LBh6ukwqlevrnEjyKRJk3Do0CF88MEHcHZ2xoMHD/DTTz+hQoUKaNasWb7tz5gxAwEBAWjSpAn69eunnnLHwsJCp88HNjAwwLhx4yT3a9++PSZNmoQ+ffqgadOmuHjxIlavXq2ufOSoVq0aLC0tsWDBApiZmaFs2bJo1KiR1uOF9u3bh59++gkTJ05UTwG0dOlStGrVCuPHj89z3kIpAwcOxM8//4yQkBCcOXMGlStXxoYNG3D06FHMnj37rW4OeJNatWqhcePGCAsLU1fV1q5dq06eCuOTTz7B+vXr8dlnn2H//v3w8fFBdnY2rl27hvXr12Pnzp2oX78+vL29ERQUhJ9++gkpKSlo2rQp9u7di1u3bml1vrNnz2LVqlVQqVRITk7GqVOn1DeyrFy5UmPak1GjRuGPP/5A+/bt1dPUPH36FBcvXsSGDRtw584d2NjYoHXr1vjkk0/w448/4ubNm2jXrh1UKhUOHz6M1q1b5/tEppo1a6JVq1aoV68eypUrh9OnT2PDhg1vfILTu/yuKAxzc3PMnz8fn3zyCerWrYvu3bvD1tYWcXFx2LZtG3x8fDB37lwAwLx589CsWTN4eHhgwIABqFq1Ku7fv4+oqCjcu3dPY+7UvKxYsQJt27ZFYGAgOnToAF9fX5QtWxY3b97E2rVrER8fn+9cjW3btlVXBz/99FOkpaVh0aJFsLOz00hily9fjp9++gmdO3dGtWrV8OTJEyxatAjm5ubqBL5///54/Pgx2rRpgwoVKuDu3buYM2cOvL29NarBhVXQzwhRkZLrtm19d+PGDTFgwABRuXJlYWRkJMzMzISPj4+YM2eOxlQTWVlZIiIiQlSpUkUYGhqKihUrirCwMI19hMh7ChYhck/T8KYpRnbt2iVq164tjIyMhJubm1i1alWuKSn27t0rOnbsKJycnISRkZFwcnISQUFBGtOP5DXljhBC7NmzR/j4+AgTExNhbm4uOnToIK5cuaKxT37TTeQ3rcvrXp1yJz/5TbkzYsQI4ejoKExMTISPj4+IiorKc6qcLVu2iJo1a4rSpUtr/JwtW7YUtWrVyvOcr7aTmpoqnJ2dRd26dUVWVpbGfsOHDxcGBgYiKirqjT9Dfr/v+/fviz59+ggbGxthZGQkPDw8cv0eCjLNTH7ymnJHCCFiYmKEn5+fUCqVwt7eXnz11Vdi9+7deU65k9d7lNeUT5mZmWLatGmiVq1aQqlUCisrK1GvXj0RERGhnv5GCCHS09PFsGHDhLW1tShbtqzo0KGD+Pvvv7WacidnKV26tChXrpxo1KiRCAsLE3fv3s3zuCdPnoiwsDDh4uIijIyMhI2NjWjatKn47rvvRGZmpnq/Fy9eiBkzZogaNWoIIyMjYWtrKwICAsSZM2fU+7w+5c4333wjGjZsKCwtLYWJiYmoUaOGmDJlika7eU0VU9TfFVLeNOVOflPR7N+/X/j7+wsLCwthbGwsqlWrJkJCQsTp06c19ouJiRG9e/cWDg4OwtDQUJQvX160b99ebNiwoUCxPXv2THz33XeiQYMGwtTUVBgZGQlXV1cxdOhQcevWLfV+eb2Pf/zxh/D09BTGxsaicuXKYtq0aWLJkiUa3z9nz54VQUFBolKlSkKpVAo7OzvRvn17jZ9jw4YNom3btsLOzk4YGRmJSpUqiU8//VTEx8drvB+vf0YKOuWOEAX/jAAQgwcPLtB7R/QmCiGKaOQzEREREZVYHNNIRERERJKYNBIRERGRJCaNRERERCSJSSMRERERSWLSSERERESSmDQSERERkSQmjUREREQkqUQ+EcakTv5PTiCSS9KpuXKHQERUrBnLmJXoMndIP1cyvv9ZaSQiIiIiSSWy0khERESkFQXraFKYNBIREREpFHJHUOwxrSYiIiIiSaw0EhEREbF7WhLfISIiIiKSxEojEREREcc0SmKlkYiIiIgksdJIRERExDGNkvgOEREREZEkVhqJiIiIOKZREpNGIiIiInZPS+I7RERERESSWGkkIiIiYve0JFYaiYiIiEgSK41EREREHNMoie8QEREREUlipZGIiIiIYxolsdJIRERERJJYaSQiIiLimEZJTBqJiIiI2D0tiWk1EREREUlipZGIiIiI3dOS+A4RERERkSRWGomIiIhYaZTEd4iIiIiIJLHSSERERGTAu6elsNJIRERERJJYaSQiIiLimEZJTBqJiIiIOLm3JKbVRERERCSJSSMRERGRwkB3i5YOHTqEDh06wMnJCQqFAps3b9YMVaHIc5kxY0a+bYaHh+fav0aNGlrFxaSRiIiIqBh5+vQpvLy8MG/evDy3x8fHayxLliyBQqFAly5d3thurVq1NI47cuSIVnFxTCMRERFRMRrTGBAQgICAgHy3Ozg4aLzesmULWrdujapVq76x3dKlS+c6VhusNBIRERHpUEZGBlJTUzWWjIyMImn7/v372LZtG/r16ye5782bN+Hk5ISqVauiZ8+eiIuL0+pcTBqJiIiIdDimMTIyEhYWFhpLZGRkkYS9fPlymJmZITAw8I37NWrUCMuWLcOOHTswf/58xMbGonnz5njy5EmBz8XuaSIiIiIdCgsLQ2hoqMY6pVJZJG0vWbIEPXv2hLGx8Rv3e7W729PTE40aNYKzszPWr19foColwKSRiIiISKdjGpVKZZElia86fPgwrl+/jnXr1ml9rKWlJapXr45bt24V+Bh2TxMREREVoyl3CuqXX35BvXr14OXlpfWxaWlpiImJgaOjY4GPYdJIREREVIykpaUhOjoa0dHRAIDY2FhER0dr3LiSmpqK3377Df3798+zDV9fX8ydO1f9euTIkTh48CDu3LmDY8eOoXPnzihVqhSCgoIKHBe7p4mIiIiK0ZQ7p0+fRuvWrdWvc8ZDBgcHY9myZQCAtWvXQgiRb9IXExODR48eqV/fu3cPQUFBSExMhK2tLZo1a4bjx4/D1ta2wHEphBCiED9PsWZSZ4jcIRDlknRqrvRORER6zFjGUpZJwCydtZ3+13Cdtf0usdJIREREpMOxhyUF3yEiIiIiksRKIxEREVExGtNYXLHSSERERESSWGkkIiIi4phGSUwaiYiIiJg0SuI7RERERESSWGkkIiIi4o0wklhpJCIiIiJJrDQSERERcUyjJL5DRERERCSJlUYiIiIijmmUxEojEREREUlipZGIiIiIYxolFauk8fnz58jMzNRYZ25uLlM0REREpDfYPS1J9rT62bNnGDJkCOzs7FC2bFlYWVlpLEREREQkP9mTxlGjRmHfvn2YP38+lEolFi9ejIiICDg5OWHFihVyh0dERER6QKFQ6GwpKWTvnv7zzz+xYsUKtGrVCn369EHz5s3h4uICZ2dnrF69Gj179pQ7RCIiIiK9J3ul8fHjx6hatSqAl+MXHz9+DABo1qwZDh06JGdoREREpCdYaZQme9JYtWpVxMbGAgBq1KiB9evXA3hZgbS0tJQxMiIiIiLKIXvS2KdPH5w/fx4AMHbsWMybNw/GxsYYPnw4Ro0aJXN0REREpBcUOlxKCNnHNA4fPlz9dz8/P1y7dg1nzpyBi4sLPD09ZYyMiIiIiHLInjS+ztnZGRYWFuyaJiIionemJI091BXZu6enTZuGdevWqV937doV1tbWKF++vLrbmoiIiEiXeCOMNNmTxgULFqBixYoAgN27d2P37t3466+/EBAQwDGNRERERMWE7N3TCQkJ6qRx69at6Nq1K9q2bYvKlSujUaNGMkdHRERE+qAkVQR1RfZKo5WVFf7++28AwI4dO+Dn5wcAEEIgOztbztCIiIiI6P/JXmkMDAxEjx494OrqisTERAQEBAAAzp07BxcXF5mjIyIiIn3ASqM02SuNs2bNwpAhQ1CzZk3s3r0bpqamAID4+HgMGjRI5uj0g0/datgw+1Pc3jUF6efmokMrzamO7MqZYWFEL9zeNQWJx2Ziy9xBqFbJVqZoSZ+tXbMaAe+1QYM6HujZ/WNcvHBB7pBIz/GaJH0ie9JoaGiIkSNH4ocffkCdOnXU64cPH47+/fvLGJn+KGuixMUb/+DLyHV5bl8/ayCqVLDBx1/+jMZBUxEX/xjbFwxFGWOjdxwp6bMdf23Hd9Mj8emgwVj72ya4udXA55/2Q2JiotyhkZ7iNVnCcHJvSbInjQAQExODoUOHws/PD35+fhg2bBhu374td1h6Y9fRK4j4aSv+2J/7f8gulezQyLMKhk1ZizNX4nDz7gMM+3YdjJWG6BpQT4ZoSV+tXL4UgR91RafOXVDNxQXjJkbA2NgYm3/fKHdopKd4TZK+kT1p3LlzJ2rWrImTJ0/C09MTnp6eOHHihLq7muSlNHo57PV55gv1OiEEMjNfoKl3NbnCIj2TlZmJq1cuo3GTpup1BgYGaNy4KS6cPydjZKSveE2WPJynUZrsN8KMHTsWw4cPx9SpU3OtHzNmDN577z2ZIiMAuH4nAXHxjzF56IcY8s2veJqeiWG9WqOCgxUcbCzkDo/0RFJyErKzs2Ftba2x3traGrGx7JWgd4/XJOkj2SuNV69eRb9+/XKt79u3L65cuSJ5fEZGBlJTUzUWoeJUPUXlxQsVuo9YBBdnO8QfmoHHUTPRon517DhyGSqhkjs8IiKiIsFKozTZK422traIjo6Gq6urxvro6GjY2dlJHh8ZGYmIiAiNdaXsG8DQsWGRxqnPzl39G427T4W5qTGMDEvjUVIaDq0YiTNX4uQOjfSElaUVSpUqlesGg8TERNjY2MgUFekzXpMlT0lK7nRF9krjgAEDMHDgQEybNg2HDx/G4cOHMXXqVHz66acYMGCA5PFhYWFISUnRWErb8wYNXUhNe45HSWmoVskWdWtWwtYDnFqC3g1DIyO416yFE8ej1OtUKhVOnIiCp1edNxxJpBu8JkkfyV5pHD9+PMzMzPD9998jLCwMAODk5ITw8HAMGzZM8nilUgmlUqmxTmFQSiexllRlTYxQreL/5l2sXN4antXLIyn1Gf5OSEKgXx08TErD3wmPUdvVCd+N+gh/HriAvcevyRg16ZtPgvtg/FdjUKtWbdT28MSqlcuRnp6OTp0D5Q6N9BSvyZKFlUZpsieNCoUCw4cPx/Dhw/HkyRMAgJmZmcxR6Ze6NZ2xa/EX6tfTR3YBAKz84zgGTlwFB1tzTBsRCDtrMyQ8SsXqrScQuXCHXOGSnmoX8D6SHj/GT3N/xKNHD+FWwx0//bwY1uwKJJnwmiR9oxBCCDkDaNOmDX7//XdYWlpqrE9NTUWnTp2wb98+rds0qTOkiKIjKjpJp+bKHQIRUbFmLGMpyzr4V521nbg8SGdtv0uyj2k8cOAAMjMzc61//vw5Dh8+LENERERERPQ62XL6C688n/PKlStISEhQv87OzsaOHTtQvnx5OUIjIiIiPcMxjdJkSxq9vb3V8xe1adMm13YTExPMmTNHhsiIiIiI6HWyJY2xsbEQQqBq1ao4efIkbG3/d/eukZER7OzsUKoU74ImIiIi3WOlUZpsSaOzszOAl/NaEREREcmJSaM02W+EAYCVK1fCx8cHTk5OuHv3LgBg1qxZ2LJli8yRERERERFQDJLG+fPnIzQ0FO+//z6Sk5ORnf3yudFWVlaYPXu2vMERERGRflDocCkhZE8a58yZg0WLFuHrr7/WGMNYv359XLx4UcbIiIiIiCiH7E+EiY2NRZ06uZ/TqVQq8fTpUxkiIiIiIn3DMY3SZK80VqlSBdHR0bnW79ixA+7u7u8+ICIiIiLKRfZKY2hoKAYPHoznz59DCIGTJ0/i119/RWRkJBYvXix3eERERKQHWGmUJnulsX///pg2bRrGjRuHZ8+eoUePHliwYAF++OEHdO/eXe7wiIiIiN6pQ4cOoUOHDnBycoJCocDmzZs1toeEhKgfkJKztGvXTrLdefPmoXLlyjA2NkajRo1w8uRJreKSPWlMT09H586dcfPmTaSlpeH48eMIDQ1FhQoV5A6NiIiI9MTrSVhRLtp6+vQpvLy8MG/evHz3adeuHeLj49XLr7/++sY2161bh9DQUEycOBFnz56Fl5cX/P398eDBgwLHJXv3dMeOHREYGIjPPvsMmZmZ+PDDD2FoaIhHjx5h5syZ+Pzzz+UOkYiIiEq44tQ9HRAQgICAgDfuo1Qq4eDgUOA2Z86ciQEDBqBPnz4AgAULFmDbtm1YsmQJxo4dW6A2ZK80nj17Fs2bNwcAbNiwAfb29rh79y5WrFiBH3/8UeboiIiIiN5ORkYGUlNTNZaMjIy3avPAgQOws7ODm5sbPv/8cyQmJua7b2ZmJs6cOQM/Pz/1OgMDA/j5+SEqKqrA55Q9aXz27BnMzMwAALt27UJgYCAMDAzQuHFj9dNhiIiIiHRKh5N7R0ZGwsLCQmOJjIwsdKjt2rXDihUrsHfvXkybNg0HDx5EQECA+gEpr3v06BGys7Nhb2+vsd7e3h4JCQkFPq/s3dMuLi7YvHkzOnfujJ07d2L48OEAgAcPHsDc3Fzm6IiIiIjeTlhYGEJDQzXWKZXKQrf36o3CHh4e8PT0RLVq1XDgwAH4+voWul0pslcaJ0yYgJEjR6Jy5cpo1KgRmjRpAuBl1TGvSb+JiIiIipoub4RRKpUwNzfXWN4maXxd1apVYWNjg1u3buW53cbGBqVKlcL9+/c11t+/f1+rcZGyJ40fffQR4uLicPr0aezYsUO93tfXF7NmzZIxMiIiIqLi7969e0hMTISjo2Oe242MjFCvXj3s3btXvU6lUmHv3r3qYl1ByN49DQAODg65Mt2GDRvKFA0RERHpm+J093RaWppG1TA2NhbR0dEoV64cypUrh4iICHTp0gUODg6IiYnB6NGj4eLiAn9/f/Uxvr6+6Ny5M4YMGQLg5cNUgoODUb9+fTRs2BCzZ8/G06dP1XdTF0SxSBqJiIiI6KXTp0+jdevW6tc54yGDg4Mxf/58XLhwAcuXL0dycjKcnJzQtm1bTJ48WaPLOyYmBo8ePVK/7tatGx4+fIgJEyYgISEB3t7e2LFjR66bY95EIYQQRfDzFSsmdYbIHQJRLkmn5sodAhFRsWYsYymr4uAtOmv773kdddb2u8RKIxEREVHx6Z0utmS/EYaIiIiIij9WGomIiEjvFacbYYorVhqJiIiISBIrjURERKT3WGmUxkojEREREUlipZGIiIj0HiuN0lhpJCIiIiJJrDQSERGR3mOlURqTRiIiIiLmjJLYPU1EREREklhpJCIiIr3H7mlprDQSERERkSRWGomIiEjvsdIojZVGIiIiIpLESiMRERHpPRYapbHSSERERESSWGkkIiIivccxjdKYNBIREZHeY84ojd3TRERERCSJlUYiIiLSe+yelsZKIxERERFJYqWRiIiI9B4LjdJYaSQiIiIiSaw0EhERkd4zMGCpUQorjUREREQkiZVGIiIi0nsc0yiNSSMRERHpPU65I43d00REREQkiZVGIiIi0nssNEpjpZGIiIiIJLHSSERERHqPYxqlsdJIRERERJJYaSQiIiK9x0qjNFYaiYiIiEgSK41ERESk91holMakkYiIiPQeu6elsXuaiIiIiCSx0khERER6j4VGaaw0EhEREZEkVhqJiIhI73FMozRWGomIiIhIEiuNREREpPdYaJTGSiMRERERSWKlkYiIiPQexzRKY6WRiIiIiCSx0khERER6j4VGaUwaiYiISO+xe1oau6eJiIiISBIrjURERKT3WGiUViKTxqRTc+UOgSgXn8j9codApOFoWGu5QyCiPBw6dAgzZszAmTNnEB8fj02bNqFTp04AgKysLIwbNw7bt2/H7du3YWFhAT8/P0ydOhVOTk75thkeHo6IiAiNdW5ubrh27VqB42L3NBEREek9hUKhs0VbT58+hZeXF+bNm5dr27Nnz3D27FmMHz8eZ8+exe+//47r16/jww8/lGy3Vq1aiI+PVy9HjhzRKq4SWWkkIiIi+q8KCAhAQEBAntssLCywe/dujXVz585Fw4YNERcXh0qVKuXbbunSpeHg4FDouFhpJCIiIr2nUOhuycjIQGpqqsaSkZFRZLGnpKRAoVDA0tLyjfvdvHkTTk5OqFq1Knr27Im4uDitzsOkkYiIiEiHIiMjYWFhobFERkYWSdvPnz/HmDFjEBQUBHNz83z3a9SoEZYtW4YdO3Zg/vz5iI2NRfPmzfHkyZMCn4vd00RERKT3dDlPY1hYGEJDQzXWKZXKt243KysLXbt2hRAC8+fPf+O+r3Z3e3p6olGjRnB2dsb69evRr1+/Ap2PSSMRERHpPV1OuaNUKoskSXxVTsJ49+5d7Nu3741VxrxYWlqievXquHXrVoGPYfc0ERER0X9ITsJ48+ZN7NmzB9bW1lq3kZaWhpiYGDg6Ohb4GCaNREREpPeK05Q7aWlpiI6ORnR0NAAgNjYW0dHRiIuLQ1ZWFj766COcPn0aq1evRnZ2NhISEpCQkIDMzEx1G76+vpg793/zVo8cORIHDx7EnTt3cOzYMXTu3BmlSpVCUFBQgeNi9zQRERFRMXL69Gm0bv2/yfdzxkMGBwcjPDwcf/zxBwDA29tb47j9+/ejVatWAICYmBg8evRIve3evXsICgpCYmIibG1t0axZMxw/fhy2trYFjotJIxEREek9Xd4Io61WrVpBCJHv9jdty3Hnzh2N12vXrn3bsNg9TURERETSWGkkIiIivVeMCo3FFiuNRERERCSJlUYiIiLSe8VpTGNxxaSRiIiI9B5zRmnsniYiIiIiSaw0EhERkd5j97Q0VhqJiIiISBIrjURERKT3WGiUxkojEREREUlipZGIiIj0ngFLjZJYaSQiIiIiSaw0EhERkd5joVEak0YiIiLSe5xyRxq7p4mIiIhIEiuNREREpPcMWGiUxEojEREREUlipZGIiIj0Hsc0SmOlkYiIiIgksdJIREREeo+FRmmsNBIRERGRJFYaiYiISO8pwFKjFCaNREREpPc45Y40dk8TERERkSRWGomIiEjvccodaaw0EhEREZEkVhqJiIhI77HQKI2VRiIiIiKSxEojERER6T0DlholsdJIRERERJJYaSQiIiK9x0KjNCaNREREpPc45Y60AiWNFy5cKHCDnp6ehQ6GiIiIiIqnAiWN3t7eUCgUEELkuT1nm0KhQHZ2dpEGSERERKRrLDRKK1DSGBsbq5OTZ2VloV27dliwYAFcXV11cg4iIiIiensFShqdnZ11cnJDQ0Otur6JiIiIdIFT7kgr1JQ7K1euhI+PD5ycnHD37l0AwOzZs7Flyxat2+rVqxd++eWXwoRBRERERO+I1ndPz58/HxMmTMCXX36JKVOmqMcwWlpaYvbs2ejYsaNW7b148QJLlizBnj17UK9ePZQtW1Zj+8yZM7UNkYiIiEgrrDNK0zppnDNnDhYtWoROnTph6tSp6vX169fHyJEjtQ7g0qVLqFu3LgDgxo0bGtt4+zsRERFR8aB10hgbG4s6derkWq9UKvH06VOtA9i/f7/WxxAREREVJRaqpGk9prFKlSqIjo7OtX7Hjh1wd3d/q2Du3buHe/fuvVUbRERERNoyUOhuKSm0ThpDQ0MxePBgrFu3DkIInDx5ElOmTEFYWBhGjx6tdQAqlQqTJk2ChYUFnJ2d4ezsDEtLS0yePBkqlUrr9oiIiIio6GndPd2/f3+YmJhg3LhxePbsGXr06AEnJyf88MMP6N69u9YBfP311/jll18wdepU+Pj4AACOHDmC8PBwPH/+HFOmTNG6TSIiIiJtsHtamkLk95iXAnj27BnS0tJgZ2dX6ACcnJywYMECfPjhhxrrt2zZgkGDBuGff/7Rus3nLwodDpHO+ERy/C4VL0fDWssdApEGY61LWUWn16rzOmt7VS8vnbX9LhX61/PgwQNcv34dwMvs3NbWtlDtPH78GDVq1Mi1vkaNGnj8+HFhwyMiIiIqMBYapWk9pvHJkyf45JNP4OTkhJYtW6Jly5ZwcnJCr169kJKSonUAXl5emDt3bq71c+fOhZdXycjMiYiIiP7rCjWm8dy5c9i2bRuaNGkCAIiKisIXX3yBTz/9FGvXrtWqvenTp+ODDz7Anj17NNr7+++/sX37dm3DIyIiItIaxzRK0zpp3Lp1K3bu3IlmzZqp1/n7+2PRokVo166d1gG0bNkSN27cwLx583Dt2jUAQGBgIAYNGgQnJyet2yMiIiKioqd10mhtbQ0LC4tc6y0sLGBlZVWoIJycnHiXNBEREcmmJM2nqCtaJ43jxo1DaGgoVq5cCQcHBwBAQkICRo0ahfHjxxeojQsXLhT4fJ6entqGSERERKQVdk9LK1DSWKdOHY038+bNm6hUqRIqVaoEAIiLi4NSqcTDhw/x6aefSrbn7e0NhUIBqdl+FAoFsrOzCxIiERERUYlw6NAhzJgxA2fOnEF8fDw2bdqETp06qbcLITBx4kQsWrQIycnJ8PHxwfz58+Hq6vrGdufNm4cZM2YgISEBXl5emDNnDho2bFjguAqUNL4aaFGIjY0t0vaIiIiI3kZxqjM+ffoUXl5e6Nu3LwIDA3Ntnz59On788UcsX74cVapUwfjx4+Hv748rV67A2Ng4zzbXrVuH0NBQLFiwAI0aNcLs2bPh7++P69evF3i+7bea3Lu44uTeVBxxcm8qbji5NxU3ck7u3XftRZ21vaS7R6GPVSgUGpVGIQScnJwwYsQIjBw5EgCQkpICe3t7LFu2LN+n8zVq1AgNGjRQT3OoUqlQsWJFDB06FGPHji1QLFrP06gLMTExGDp0KPz8/ODn54dhw4YhJiZG7rCIiIhITxgoFDpbMjIykJqaqrFkZGQUKs7Y2FgkJCTAz89Pvc7CwgKNGjVCVFRUnsdkZmbizJkzGscYGBjAz88v32PyfI+0DTY7OxvfffcdGjZsCAcHB5QrV05j0dbOnTtRs2ZNnDx5Ep6envD09MSJEydQq1Yt7N69W+v2iIiIiIqTyMhIWFhYaCyRkZGFaishIQEAYG9vr7He3t5eve11jx49QnZ2tlbH5EXrQnBERAQWL16MESNGYNy4cfj6669x584dbN68GRMmTNC2OYwdOxbDhw/H1KlTc60fM2YM3nvvPa3bJCIiItKGLm+eDgsLQ2hoqMY6pVKpuxPqiNaVxtWrV2PRokUYMWIESpcujaCgICxevBgTJkzA8ePHtQ7g6tWr6NevX671ffv2xZUrV7Ruj4iIiKg4USqVMDc311gKmzTmTHd4//59jfX3799Xb3udjY0NSpUqpdUxedE6aUxISICHx8sBnaampurnTbdv3x7btm3TtjnY2toiOjo61/ro6OgC381DRERE9DYUCoXOlqJUpUoVODg4YO/evep1qampOHHihPpxzK8zMjJCvXr1NI5RqVTYu3dvvsfkRevu6QoVKiA+Ph6VKlVCtWrVsGvXLtStWxenTp0qVNY8YMAADBw4ELdv30bTpk0BAEePHsW0adNylXKJiIiISrq0tDTcunVL/To2NhbR0dEoV64cKlWqhC+//BLffPMNXF1d1VPuODk5aUyR6Ovri86dO2PIkCEAgNDQUAQHB6N+/fpo2LAhZs+ejadPn6JPnz4FjkvrpLFz587Yu3cvGjVqhKFDh6JXr1745ZdfEBcXh+HDh2vbHMaPHw8zMzN8//33CAsLA/DysYLh4eEYNmyY1u0RERERaas4PRDm9OnTaN36f1Ni5RTRgoODsWzZMowePRpPnz7FwIEDkZycjGbNmmHHjh0aczTGxMTg0aNH6tfdunXDw4cPMWHCBCQkJMDb2xs7duzIdXPMm7z1PI3Hjx/HsWPH4Orqig4dOrxNU3jy5AkAwMzM7K3a4TyNb2/tmtVYvvQXPHr0ENXdamDsV+PhwUc6vhXO01hwdSpZoHeTSnB3NIOtmRIj1l/Egev/+/Ib2KIy/GvZwd7cGFnZKlyNf4Kf9sfi0r+pMkb938N5Gt8evyuLlpzzNH6+UXf3UczvUlNnbb9Lbz1PY+PGjREaGopGjRrh22+/1fr42NhY3Lx5E8DLZDEnYbx58ybu3LnztuFRIez4azu+mx6JTwcNxtrfNsHNrQY+/7QfEhMT5Q6N9ISJYSncuJ+GaX/dyHN73ONnmLbjJrr9fBL9lp9FfMpzzOvpBcsyhu84UtJn/K4kfVNkk3vHx8dj/PjxWh8XEhKCY8eO5Vp/4sQJhISEFEFkpK2Vy5ci8KOu6NS5C6q5uGDcxAgYGxtj8+8b5Q6N9MSxmMeYfyAW+1+pLr5qx6UHOBmbhH+Sn+P2w2eYuesWTI1Lw9XO9B1HSvqM35Uli0Khu6WkkP2JMOfOnYOPj0+u9Y0bN87zrmrSrazMTFy9chmNmzRVrzMwMEDjxk1x4fw5GSMjyltpAwUC6zrhyfMs3LyfJnc4pCf4XUn6SMbRAy8pFAr1WMZXpaSkIDs7W4aI9FtSchKys7NhbW2tsd7a2hqxsbdliooot+au1vg2sCaMDUvh0ZNMDFp1HsnpWXKHRXqC35UlT1FPjVMSyV5pbNGiBSIjIzUSxOzsbERGRqJZs2aSxxfl8xyJ6L/j1J0kBC08jT5Lz+JYTCKmdqkFK45pJCLSmQJXGqXmTHz48GGhApg2bRpatGgBNzc3NG/eHABw+PBhpKamYt++fZLHR0ZGIiIiQmPd1+MnYtyE8ELFo++sLK1QqlSpXAO5ExMTYWNjI1NURLk9z1LhXlI67iWl49I/qdg0qBE61XHE0qNxcodGeoDflSWP7FW0/4ACJ43nzkmP0WjRooXWAdSsWRMXLlzA3Llzcf78eZiYmKB3794YMmQIypUrJ3l8Xs9zFKX+e89zLC4MjYzgXrMWThyPQhtfPwAvZ40/cSIK3YN6yRwdUf4MFAoYluLXPr0b/K4kfVTgpHH/ft3NMefk5FSo6XqAl89zfP1JNJyn8e18EtwH478ag1q1aqO2hydWrVyO9PR0dOocKHdopCdMDEuhYjkT9WsnS2NUtzdFanoWktOz0K9ZZRy88QiP0jJgaWKIrg0qwNbcCHuuPpAxatI3/K4sWTimUZosN8JcuHABtWvXhoGBAS5cuPDGfT05Seo71y7gfSQ9foyf5v6IR48ewq2GO376eTGs2eVC70hNJzMs7F1H/XpEW1cAwJ/n4/HtthuobFMG7T1rw7KMIVLSs3D531T0X3YOtx8+kytk0kP8rixZDJgzSnrrJ8IUhoGBARISEmBnZwcDAwMoFArkFYZCoSjUHdSsNFJxxCfCUHHDJ8JQcSPnE2G+3HJNZ23P7lhDZ22/S7L8emJjY2Fra6v+OxEREZGcWGmUJkvS6OzsnOffiYiIiKh4kv1Ww+XLl2Pbtm3q16NHj4alpSWaNm2Ku3fvyhgZERER6QuFQqGzpaQoVNJ4+PBh9OrVC02aNME///wDAFi5ciWOHDmidVvffvstTExe3iUZFRWFuXPnYvr06bCxscHw4cMLEx4RERERFTGtk8aNGzfC398fJiYmOHfunPrpKykpKYWaNufvv/+Gi4sLAGDz5s346KOPMHDgQERGRuLw4cNat0dERESkLQOF7paSQuuk8ZtvvsGCBQuwaNEiGBr+75FdPj4+OHv2rNYBmJqaqmfU37VrF9577z0AgLGxMdLT07Vuj4iIiIiKntY3wly/fj3PJ79YWFggOTlZ6wDee+899O/fH3Xq1MGNGzfw/vvvAwAuX76MypUra90eERERkbZK0NBDndG60ujg4IBbt27lWn/kyBFUrVpV6wDmzZuHpk2b4uHDh9i4cSOsra0BAGfOnEFQUJDW7RERERFpy0Ch0NlSUmhdaRwwYAC++OILLFmyBAqFAv/++y+ioqIwcuRIjB8/Xqu2Xrx4gR9//BFjxoxBhQoVNLZFRERoGxoRERER6YjWSePYsWOhUqng6+uLZ8+eoUWLFlAqlRg5ciSGDh2q3clLl8b06dPRu3dvbcMgIiIiKjKyz0H4H6B10qhQKPD1119j1KhRuHXrFtLS0lCzZk2YmpoWKgBfX18cPHiQ4xeJiIiIirFCPxHGyMgINWvWfOsAAgICMHbsWFy8eBH16tVD2bJlNbZ/+OGHb30OIiIiojcpQUMPdUbrpLF169ZvnN183759WrU3aNAgAMDMmTNzbVMoFMjOztYuQCIiIiIqclonjd7e3hqvs7KyEB0djUuXLiE4OFjrAFQqldbHEBERERWlknSXs65onTTOmjUrz/Xh4eFIS0t7q2CeP38OY2Pjt2qDiIiIiIpekd0s1KtXLyxZskTr47KzszF58mSUL18epqamuH37NgBg/Pjx+OWXX4oqPCIiIqJ8KRS6W0qKIksao6KiClUlnDJlCpYtW4bp06fDyMhIvb527dpYvHhxUYVHRERElC8+e1qa1t3TgYGBGq+FEIiPj8fp06e1ntwbAFasWIGFCxfC19cXn332mXq9l5cXrl27pnV7RERERFT0tE4aLSwsNF4bGBjAzc0NkyZNQtu2bbUO4J9//oGLi0uu9SqVCllZWVq3R0RERKQt3ggjTaukMTs7G3369IGHhwesrKyKJICaNWvi8OHDcHZ21li/YcMG1KlTp0jOQURERERvR6uksVSpUmjbti2uXr1aZEnjhAkTEBwcjH/++QcqlQq///47rl+/jhUrVmDr1q1Fcg4iIiKiN2GhUZrWN8LUrl1bfYdzUejYsSP+/PNP7NmzB2XLlsWECRNw9epV/Pnnn3jvvfeK7DxEREREVHhaj2n85ptvMHLkSEyePDnPx/6Zm5tr1V7//v3Rq1cv7N69W9tQiIiIiIpESbrLWVcKXGmcNGkSnj59ivfffx/nz5/Hhx9+iAoVKsDKygpWVlawtLQsVJf1w4cP0a5dO1SsWBGjR4/G+fPntW6DiIiIiHSrwJXGiIgIfPbZZ9i/f3+RBrBlyxYkJSXht99+w5o1a/D999+jRo0a6NmzJ3r06IHKlSsX6fmIiIiIXqcAS41SFEIIUZAdDQwMkJCQADs7O50GdO/ePfz6669YsmQJbt68iRcvXmjdxnPtDyHSOZ/Iov0PF9HbOhrWWu4QiDQYaz1oruhM3Rejs7bHtqmms7bfJa1uhFHo+NairKwsnD59GidOnMCdO3dgb2+v0/MRERERUcFoldNXr15dMnF8/Pix1kHs378fa9aswcaNG6FSqRAYGIitW7eiTZs2WrdFREREpC3eCCNNq6QxIiIi1xNh3lb58uXx+PFjtGvXDgsXLkSHDh2gVCqL9BxERERE9Ha0Shq7d+9e5GMaw8PD8fHHH8PS0rJI2yUiIiIqKF0PwSsJCpw06urNHDBggE7aJSIiIqKiU+CksYA3WRMRERH953BMo7QCJ40qlUqXcRARERFRMSbjjEhERERExQOHNEpj0khERER6z4BZoyStJvcmIiIiIv3ESiMRERHpPd4II42VRiIiIiKSxEojERER6T0OaZTGSiMRERFRMVG5cmUoFIpcy+DBg/Pcf9myZbn2NTY21klsrDQSERGR3jNA8Sg1njp1CtnZ2erXly5dwnvvvYePP/4432PMzc1x/fp19WtdPcWPSSMRERFRMWFra6vxeurUqahWrRpatmyZ7zEKhQIODg66Do3d00REREQKhe6WjIwMpKamaiwZGRmSMWVmZmLVqlXo27fvG6uHaWlpcHZ2RsWKFdGxY0dcvny5KN8aNSaNREREpPcMFLpbIiMjYWFhobFERkZKxrR582YkJycjJCQk333c3NywZMkSbNmyBatWrYJKpULTpk1x7969Inx3XlIIIUSRtyqz5y/kjoAoN5/I/XKHQKThaFhruUMg0mAs46C5BVF3dNZ2n7qOuSqLSqUSSqXyjcf5+/vDyMgIf/75Z4HPlZWVBXd3dwQFBWHy5MmFijc/HNNIREREek+XjxEsSIL4urt372LPnj34/ffftTrO0NAQderUwa1bt7Q6riDYPU1ERERUzCxduhR2dnb44IMPtDouOzsbFy9ehKOjY5HHxEojERER6b3iNLm3SqXC0qVLERwcjNKlNVO13r17o3z58uoxkZMmTULjxo3h4uKC5ORkzJgxA3fv3kX//v2LPC4mjURERETFyJ49exAXF4e+ffvm2hYXFwcDg/91FCclJWHAgAFISEiAlZUV6tWrh2PHjqFmzZpFHhdvhCF6R3gjDBU3vBGGihs5b4T55WScztru17CSztp+lzimkYiIiIgksXuaiIiI9F5xGtNYXDFpJCIiIr3HrldpfI+IiIiISBIrjURERKT33vRsZ3qJlUYiIiIiksRKIxEREek91hmlsdJIRERERJJYaSQiIiK9Z8AxjZJYaSQiIiIiSaw0EhERkd5jnVEak0YiIiLSe+ydlsbuaSIiIiKSxEojERER6T1O7i2NlUYiIiIiksRKIxEREek9VtGk8T0iIiIiIkmsNBIREZHe45hGaaw0EhEREZEkVhqJiIhI77HOKI2VRiIiIiKSxEojERER6T2OaZTGpJHoHTka1lruEIg0+ETulzsEIg1nxsv3PcmuV2l8j4iIiIhIEiuNREREpPfYPS2NlUYiIiIiksRKIxEREek91hmlsdJIRERERJJYaSQiIiK9xyGN0lhpJCIiIiJJrDQSERGR3jPgqEZJTBqJiIhI77F7Whq7p4mIiIhIEiuNREREpPcU7J6WxEojEREREUlipZGIiIj0Hsc0SmOlkYiIiIgksdJIREREeo9T7khjpZGIiIiIJLHSSERERHqPYxqlMWkkIiIivcekURq7p4mIiIhIEiuNREREpPc4ubc0VhqJiIiISBIrjURERKT3DFholMRKIxERERFJYqWRiIiI9B7HNEpjpZGIiIiIJLHSSERERHqP8zRKY9JIREREeo/d09LYPU1ERERUTISHh0OhUGgsNWrUeOMxv/32G2rUqAFjY2N4eHhg+/btOomNSSMRERHpPQOF7hZt1apVC/Hx8erlyJEj+e577NgxBAUFoV+/fjh37hw6deqETp064dKlS2/xbuSNSSMRERFRMVK6dGk4ODioFxsbm3z3/eGHH9CuXTuMGjUK7u7umDx5MurWrYu5c+cWeVxMGomIiEjvKXT4JyMjA6mpqRpLRkZGvrHcvHkTTk5OqFq1Knr27Im4uLh8942KioKfn5/GOn9/f0RFRRXZe5ODSSMRERGRDkVGRsLCwkJjiYyMzHPfRo0aYdmyZdixYwfmz5+P2NhYNG/eHE+ePMlz/4SEBNjb22uss7e3R0JCQpH/HLx7moiIiPSeLqfcCQsLQ2hoqMY6pVKZ574BAQHqv3t6eqJRo0ZwdnbG+vXr0a9fP90FWQBMGomIiIh0SKlU5pskSrG0tET16tVx69atPLc7ODjg/v37Guvu378PBweHQp3vTdg9TURERHpPocPlbaSlpSEmJgaOjo55bm/SpAn27t2rsW737t1o0qTJW545NyaNREREpPcMFAqdLdoYOXIkDh48iDt37uDYsWPo3LkzSpUqhaCgIABA7969ERYWpt7/iy++wI4dO/D999/j2rVrCA8Px+nTpzFkyJAifX8Adk8TERERFRv37t1DUFAQEhMTYWtri2bNmuH48eOwtbUFAMTFxcHA4H81v6ZNm2LNmjUYN24cvvrqK7i6umLz5s2oXbt2kcemEEKIIm9VZs9fyB0BEVHx5xO5X+4QiDScGd9atnMfv5Wss7Ybu1jqrO13id3TRERERCSJ3dNEREREOpxyp6RgpZGIiIiIJLHSSERERHpPwVKjJFYaiYiIiEgSK41ERESk93T5GMGSgkkjERER6T3mjNLYPU1EREREklhpJCIiImKpURIrjUREREQkiZVGIiIi0nucckcaK41EREREJEn2SmN2djZmzZqF9evXIy4uDpmZmRrbHz9+LFNkREREpC845Y402SuNERERmDlzJrp164aUlBSEhoYiMDAQBgYGCA8Plzs8IiIiIkIxSBpXr16NRYsWYcSIEShdujSCgoKwePFiTJgwAcePH5c7PCIiItIDCh0uJYXsSWNCQgI8PDwAAKampkhJSQEAtG/fHtu2bZMzNCIiItIXzBolyZ40VqhQAfHx8QCAatWqYdeuXQCAU6dOQalUyhkaEREREf0/2ZPGzp07Y+/evQCAoUOHYvz48XB1dUXv3r3Rt29fmaMjIiIifaDQ4Z+SQva7p6dOnar+e7du3eDs7Ixjx47B1dUVHTp0kDEyIiIiIsohe9L4usaNG6Nx48Zyh0FERER6hFPuSJO9ezoyMhJLlizJtX7JkiWYNm2aDBERERER0etkTxp//vln1KhRI9f6WrVqYcGCBTJERERERPqGN09Lkz1pTEhIgKOjY671tra26ruqiYiIiEhesieNFStWxNGjR3OtP3r0KJycnGSIiIiIiPQOS42SZL8RZsCAAfjyyy+RlZWFNm3aAAD27t2L0aNHY8SIETJHR0RERPqgJE2NoyuyJ42jRo1CYmIiBg0ahMzMTACAsbExxowZg7CwMJmjIyIiIiIAUAghhNxBAEBaWhquXr0KExMTuLq6vtXTYJ6/KMLAiIhKKJ/I/XKHQKThzPjWsp374r00nbXtUcFUZ22/S7JXGnOYmpqiQYMGcodBRERERHmQJWkMDAzEsmXLYG5ujsDAwDfu+/vvv7+jqIiIiEhfcUSjNFmSRgsLCyj+f+p1CwsLOUIgIiIiIi3IkjQuXbo0z78TERERyYKlRkmyz9NIRERERMWf7DfC3L9/HyNHjsTevXvx4MEDvH4zd3Z2tkyR6be1a1Zj+dJf8OjRQ1R3q4GxX42Hh6en3GGRnuN1SXKpU8kCvZtUgrujGWzNlBix/iIOXH+k3j6wRWX417KDvbkxsrJVuBr/BD/tj8Wlf1NljJq0wXkapcmeNIaEhCAuLg7jx4+Ho6OjeqwjyWfHX9vx3fRIjJsYAQ8PL6xeuRyff9oPW7bugLW1tdzhkZ7idUlyMjEshRv30/BHdDy+6+qRa3vc42eYtuMm/klKh9LQAD0bVcS8nl7oOO84kp9lyRAxUdGTPWk8cuQIDh8+DG9vb7lDof+3cvlSBH7UFZ06dwEAjJsYgUOHDmDz7xvRb8BAmaMjfcXrkuR0LOYxjsU8znf7jksPNF7P3HULneo4wdXOFKfuJOk6PCoCrFlJk31MY8WKFXN1SZN8sjIzcfXKZTRu0lS9zsDAAI0bN8WF8+dkjIz0Ga9L+i8pbaBAYF0nPHmehZv3dTdhNBUtPnpamuxJ4+zZszF27FjcuXNH7lAIQFJyErKzs3N191lbW+PRo0f5HEWkW7wu6b+guas1Do9pjqivWqJHo4oYtOo8ktPZNU0lh+zd0926dcOzZ89QrVo1lClTBoaGhhrbHz/OvzsAADIyMpCRkaGxTpRSvtVjCImIiLR16k4SghaehmUZQ3Su44ipXWoheMkZJHFM439DSSoJ6ojsSePs2bPf6vjIyEhERERorPt6/ESMmxD+Vu3qKytLK5QqVQqJiYka6xMTE2FjYyNTVKTveF3Sf8HzLBXuJaXjXlI6Lv2Tik2DGqFTHUcsPRond2hERUL2pDE4OPitjg8LC0NoaKjGOlGKVcbCMjQygnvNWjhxPAptfP0AACqVCidORKF7UC+ZoyN9xeuS/osMFAoYlpJ9FBgVEKfckSZL0piamgpzc3P1398kZ7/8KJW5u6Kfv3i7+PTdJ8F9MP6rMahVqzZqe3hi1crlSE9PR6fOb35OOJEu8bokOZkYlkLFcibq106Wxqhub4rU9Cwkp2ehX7PKOHjjER6lZcDSxBBdG1SArbkR9lx98IZWif5bZEkaraysEB8fDzs7O1haWuY5N6MQAgqFgpN7y6BdwPtIevwYP839EY8ePYRbDXf89PNiWLMbkGTE65LkVNPJDAt711G/HtHWFQDw5/l4fLvtBirblEF7z9qwLGOIlPQsXP43Ff2XncPth8/kCpm0xCl3pCmEDPPdHDx4ED4+PihdujQOHjz4xn1btmypdfusNBIRSfOJ3C93CEQazoxvLdu5ryfoLsF3cyijs7bfJVkqja8mgoVJComIiIiKEguN0mS/EebChQt5rlcoFDA2NkalSpU4fQ4RERHpFrNGSbInjd7e3m983rShoSG6deuGn3/+GcbGxu8wMiIiIiLKIftcAJs2bYKrqysWLlyI6OhoREdHY+HChXBzc8OaNWvwyy+/YN++fRg3bpzcoRIREVEJpdDhn5JC9krjlClT8MMPP8Df31+9zsPDAxUqVMD48eNx8uRJlC1bFiNGjMB3330nY6RERERE+kv2pPHixYtwdnbOtd7Z2RkXL14E8LILOz4+/l2HRkRERHqCU+5Ik717ukaNGpg6dSoyMzPV67KysjB16lTUqFEDAPDPP//A3t5erhCJiIiI9J7sSeO8efOwdetWVKhQAX5+fvDz80OFChWwdetWzJ8/HwBw+/ZtDBo0SOZIiYiIqKRS6HDRRmRkJBo0aAAzMzPY2dmhU6dOuH79+huPWbZsGRQKhcaii5uHZe+ebtq0KWJjY7F69WrcuHEDAPDxxx+jR48eMDMzAwB88skncoZIRERE9E4cPHgQgwcPRoMGDfDixQt89dVXaNu2La5cuYKyZcvme5y5ublGcvmmmWkKS9akMSsrCzVq1MDWrVvx2WefyRkKERER6bNiMqZxx44dGq+XLVsGOzs7nDlzBi1atMj3OIVCAQcHB53GJmv3tKGhIZ4/fy5nCEREREQ6nXInIyMDqampGktGRkaB4kpJSQEAlCtX7o37paWlwdnZGRUrVkTHjh1x+fLlt35PXif7mMbBgwdj2rRpePGCD4wmIiKikicyMhIWFhYaS2RkpORxKpUKX375JXx8fFC7du1893Nzc8OSJUuwZcsWrFq1CiqVCk2bNsW9e/eK8seAQgghirRFLXXu3Bl79+6FqakpPDw8cvXX//7771q3+Zz5JxGRJJ/I/XKHQKThzPjWsp079pHuej6dzBS5KotKpVLyMcmff/45/vrrLxw5cgQVKlQo8PmysrLg7u6OoKAgTJ48uVAx50X2G2EsLS3RpUsXucMgIiIi0omCJIivGzJkCLZu3YpDhw5plTACL4f/1alTB7du3dLqOCmyJ41Lly6VOwQiIiLSc8XkPhgIITB06FBs2rQJBw4cQJUqVbRuIzs7GxcvXsT7779fpLHJnjQSERER0UuDBw/GmjVrsGXLFpiZmSEhIQEAYGFhARMTEwBA7969Ub58efW4yEmTJqFx48ZwcXFBcnIyZsyYgbt376J///5FGpssSWPdunWxd+9eWFlZoU6dOm+cS+js2bPvMDIiIiLSS8Wk1JjzYJNWrVpprF+6dClCQkIAAHFxcTAw+N+9zElJSRgwYAASEhJgZWWFevXq4dixY6hZs2aRxiZL0tixY0d1336nTp3kCIGIiIio2CnI/ckHDhzQeD1r1izMmjVLRxH9jyxJ48SJE9V///vvv9GzZ0+0bi3fHVNERESk3xTFpdRYjMk+T+PDhw8REBCAihUrYvTo0Th//rzcIREREZGeUSh0t5QUsieNW7ZsQXx8PMaPH4+TJ0+ibt26qFWrFr799lvcuXNH7vCIiIiICMUgaQQAKysrDBw4EAcOHMDdu3cREhKClStXwsXFRe7QiIiISA8odLiUFMUiacyRlZWF06dP48SJE7hz5w7s7e3lDomIiIiIUEySxv3792PAgAGwt7dHSEgIzM3NsXXr1iJ/ZiIRERFRXjimUZrsk3uXL18ejx8/Rrt27bBw4UJ06NBB60ftEBEREZFuyZ40hoeH4+OPP4alpaXcoRAREZHeKkElQR2RPWkcMGCA3CEQERERkQTZk0YiIiIiuZWksYe6wqSRiIiI9B5zRmnF4u5pIiIiIireWGkkIiIivcfuaWmsNBIRERGRJFYaiYiISO8pOKpREiuNRERERCSJlUYiIiIiFholsdJIRERERJJYaSQiIiK9x0KjNCaNREREpPc45Y40dk8TERERkSRWGomIiEjvccodaaw0EhEREZEkVhqJiIiIWGiUxEojEREREUlipZGIiIj0HguN0lhpJCIiIiJJrDQSERGR3uM8jdKYNBIREZHe45Q70tg9TURERESSWGkkIiIivcfuaWmsNBIRERGRJCaNRERERCSJSSMRERERSeKYRiIiItJ7HNMojZVGIiIiIpLESiMRERHpPc7TKI1JIxEREek9dk9LY/c0EREREUlipZGIiIj0HguN0lhpJCIiIiJJrDQSERERsdQoiZVGIiIiIpLESiMRERHpPU65I42VRiIiIiKSxEojERER6T3O0yiNlUYiIiIiksRKIxEREek9FhqlMWkkIiIiYtYoid3TRERERCSJSSMRERHpPYUO/xTGvHnzULlyZRgbG6NRo0Y4efLkG/f/7bffUKNGDRgbG8PDwwPbt28v1HnfhEkjERERUTGybt06hIaGYuLEiTh79iy8vLzg7++PBw8e5Ln/sWPHEBQUhH79+uHcuXPo1KkTOnXqhEuXLhVpXAohhCjSFouB5y/kjoCIqPjzidwvdwhEGs6Mby3buXWZOxhreQdJo0aN0KBBA8ydOxcAoFKpULFiRQwdOhRjx47NtX+3bt3w9OlTbN26Vb2ucePG8Pb2xoIFC94q9lex0khERESkQxkZGUhNTdVYMjIy8tw3MzMTZ86cgZ+fn3qdgYEB/Pz8EBUVlecxUVFRGvsDgL+/f777F1aJvHta24ye8paRkYHIyEiEhYVBqVTKHQ4Rr8kiJmdVpyThdVky6DJ3CP8mEhERERrrJk6ciPDw8Fz7Pnr0CNnZ2bC3t9dYb29vj2vXruXZfkJCQp77JyQkvF3gr2GlkfKVkZGBiIiIfP83RPSu8Zqk4ojXJUkJCwtDSkqKxhIWFiZ3WFpjTY6IiIhIh5RKZYGr0DY2NihVqhTu37+vsf7+/ftwcHDI8xgHBwet9i8sVhqJiIiIigkjIyPUq1cPe/fuVa9TqVTYu3cvmjRpkucxTZo00dgfAHbv3p3v/oXFSiMRERFRMRIaGorg4GDUr18fDRs2xOzZs/H06VP06dMHANC7d2+UL18ekZGRAIAvvvgCLVu2xPfff48PPvgAa9euxenTp7Fw4cIijYtJI+VLqVRi4sSJHNhNxQavSSqOeF1SUevWrRsePnyICRMmICEhAd7e3tixY4f6Zpe4uDgYGPyvs7hp06ZYs2YNxo0bh6+++gqurq7YvHkzateuXaRxlch5GomIiIioaHFMIxERERFJYtJIRERERJKYNBIRERGRJCaNRFSs3blzBwqFAtHR0cWyPfpvCQ8Ph7e391u3c+DAASgUCiQnJxf4mJCQEHTq1Omtz00kF94IQ7hz5w6qVKmCc+fOFcmXKVFRys7OxsOHD2FjY4PSpd9+wgde7/otLS0NGRkZsLa2fqt2MjMz8fjxY9jb20OhUBTomJSUFAghYGlp+VbnJpILp9whIlllZWXB0NAw3+2lSpUq8qcavK3MzEwYGRnJHQYVgqmpKUxNTfPdXtDfrZGRkdbXpYWFhVb7ExU37J4uQTZs2AAPDw+YmJjA2toafn5+ePr0KQBg8eLFcHd3h7GxMWrUqIGffvpJfVyVKlUAAHXq1IFCoUCrVq0AvJyBftKkSahQoQKUSqV6nqgcmZmZGDJkCBwdHWFsbAxnZ2f1RKMAMHPmTHh4eKBs2bKoWLEiBg0ahLS0tHfwTpCuLFy4EE5OTlCpVBrrO3bsiL59+wIAtmzZgrp168LY2BhVq1ZFREQEXrx4od5XoVBg/vz5+PDDD1G2bFlMmTIFSUlJ6NmzJ2xtbWFiYgJXV1csXboUQN7dyZcvX0b79u1hbm4OMzMzNG/eHDExMQCkr9u8HDx4EA0bNoRSqYSjoyPGjh2rEXOrVq0wZMgQfPnll7CxsYG/v/9bvY+kO1LX6Ovd0zldxlOmTIGTkxPc3NwAAMeOHYO3tzeMjY1Rv359bN68WeM6fL17etmyZbC0tMTOnTvh7u4OU1NTtGvXDvHx8bnOlUOlUmH69OlwcXGBUqlEpUqVMGXKFPX2MWPGoHr16ihTpgyqVq2K8ePHIysrq2jfMCJtCCoR/v33X1G6dGkxc+ZMERsbKy5cuCDmzZsnnjx5IlatWiUcHR3Fxo0bxe3bt8XGjRtFuXLlxLJly4QQQpw8eVIAEHv27BHx8fEiMTFRCCHEzJkzhbm5ufj111/FtWvXxOjRo4WhoaG4ceOGEEKIGTNmiIoVK4pDhw6JO3fuiMOHD4s1a9aoY5o1a5bYt2+fiI2NFXv37hVubm7i888/f/dvDhWZx48fCyMjI7Fnzx71usTERPW6Q4cOCXNzc7Fs2TIRExMjdu3aJSpXrizCw8PV+wMQdnZ2YsmSJSImJkbcvXtXDB48WHh7e4tTp06J2NhYsXv3bvHHH38IIYSIjY0VAMS5c+eEEELcu3dPlCtXTgQGBopTp06J69eviyVLlohr164JIaSv27zaK1OmjBg0aJC4evWq2LRpk7CxsRETJ05Ux9yyZUthamoqRo0aJa5du6Y+FxU/UtfoxIkThZeXl3pbcHCwMDU1FZ988om4dOmSuHTpkkhJSRHlypUTvXr1EpcvXxbbt28X1atX17hu9u/fLwCIpKQkIYQQS5cuFYaGhsLPz0+cOnVKnDlzRri7u4sePXponKtjx47q16NHjxZWVlZi2bJl4tatW+Lw4cNi0aJF6u2TJ08WR48eFbGxseKPP/4Q9vb2Ytq0aTp534gKgkljCXHmzBkBQNy5cyfXtmrVqmkkc0K8/DJq0qSJECL3P6I5nJycxJQpUzTWNWjQQAwaNEgIIcTQoUNFmzZthEqlKlCMv/32m7C2ti7oj0TFVMeOHUXfvn3Vr3/++Wfh5OQksrOzha+vr/j222819l+5cqVwdHRUvwYgvvzyS419OnToIPr06ZPn+V6/PsPCwkSVKlVEZmZmnvtLXbevt/fVV18JNzc3jet43rx5wtTUVGRnZwshXiaNderUye8toWLmTddoXkmjvb29yMjIUK+bP3++sLa2Funp6ep1ixYtkkwaAYhbt26pj5k3b56wt7fXOFdO0piamiqUSqVGkihlxowZol69egXen6iosXu6hPDy8oKvry88PDzw8ccfY9GiRUhKSsLTp08RExODfv36qcfymJqa4ptvvlF35+UlNTUV//77L3x8fDTW+/j44OrVqwBedrVER0fDzc0Nw4YNw65duzT23bNnD3x9fVG+fHmYmZnhk08+QWJiIp49e1b0bwC9Mz179sTGjRuRkZEBAFi9ejW6d+8OAwMDnD9/HpMmTdK41gYMGID4+HiN33v9+vU12vz888+xdu1aeHt7Y/To0Th27Fi+54+Ojkbz5s3zHAdZkOv2dVevXkWTJk00bmbw8fFBWloa7t27p15Xr169N7wrVJy86RrNi4eHh8Y4xuvXr8PT0xPGxsbqdQ0bNpQ8b5kyZVCtWjX1a0dHRzx48CDPfa9evYqMjAz4+vrm2966devg4+MDBwcHmJqaYty4cYiLi5OMg0hXmDSWEKVKlcLu3bvx119/oWbNmpgzZw7c3Nxw6dIlAMCiRYsQHR2tXi5duoTjx4+/1Tnr1q2L2NhYTJ48Genp6ejatSs++ugjAC/HobVv3x6enp7YuHEjzpw5g3nz5gF4ORaS/rs6dOgAIQS2bduGv//+G4cPH0bPnj0BvLwzNSIiQuNau3jxIm7evKnxD3DZsmU12gwICMDdu3cxfPhw/Pvvv/D19cXIkSPzPL+JiYnufrg3eD1mKr7edI3mpah+t6//R0ahUEDkM0GJ1HUcFRWFnj174v3338fWrVtx7tw5fP311/z+JFkxaSxBFAoFfHx8EBERgXPnzsHIyAhHjx6Fk5MTbt++DRcXF40l5waYnP9hZ2dnq9syNzeHk5MTjh49qnGOo0ePombNmhr7devWDYsWLcK6deuwceNGPH78GGfOnIFKpcL333+Pxo0bo3r16vj333/fwbtAumZsbIzAwECsXr0av/76K9zc3FC3bl0AL/8jcf369VzXmouLS75Vnhy2trYIDg7GqlWrMHv2bCxcuDDP/Tw9PXH48OE8bwgo6HX7Knd3d0RFRWn843706FGYmZmhQoUKb4yZiqc3XaMF4ebmhosXL6orlQBw6tSpIo3R1dUVJiYm2Lt3b57bjx07BmdnZ3z99deoX78+XF1dcffu3SKNgUhbnHKnhDhx4gT27t2Ltm3bws7ODidOnMDDhw/h7u6OiIgIDBs2DBYWFmjXrh0yMjJw+vRpJCUlITQ0FHZ2djAxMcGOHTtQoUIFGBsbw8LCAqNGjcLEiRNRrVo1eHt7Y+nSpYiOjsbq1asBvLw72tHREXXq1IGBgQF+++03ODg4wNLSEi4uLsjKysKcOXPQoUMHHD16FAsWLJD5XaKi0rNnT7Rv3x6XL19Gr1691OsnTJiA9u3bo1KlSvjoo4/UXdaXLl3CN998k297EyZMQL169VCrVi1kZGRg69atcHd3z3PfIUOGYM6cOejevTvCwsJgYWGB48ePo2HDhnBzc5O8bl83aNAgzJ49G0OHDsWQIUNw/fp1TJw4EaGhoZKJLhVf+V2jBdGjRw98/fXXGDhwIMaOHYu4uDh89913AFDgORmlGBsbY8yYMRg9ejSMjIzg4+ODhw8f4vLly+jXrx9cXV0RFxeHtWvXokGDBti2bRs2bdpUJOcmKjR5h1RSUbly5Yrw9/cXtra2QqlUiurVq4s5c+aot69evVp4e3sLIyMjYWVlJVq0aCF+//139fZFixaJihUrCgMDA9GyZUshhBDZ2dkiPDxclC9fXhgaGgovLy/x119/qY9ZuHCh8Pb2FmXLlhXm5ubC19dXnD17Vr195syZwtHRUZiYmAh/f3+xYsUKjYHj9N+VnZ0tHB0dBQARExOjsW3Hjh2iadOmwsTERJibm4uGDRuKhQsXqrcDEJs2bdI4ZvLkycLd3V2YmJiIcuXKiY4dO4rbt28LIfK+Uev8+fOibdu2okyZMsLMzEw0b95cHYfUdZtXewcOHBANGjQQRkZGwsHBQYwZM0ZkZWWpt7ds2VJ88cUXb/mu0buU3zWa140wr97RnOPo0aPC09NTGBkZiXr16ok1a9YIAOo75/O6EcbCwkKjjU2bNolX/5l9/VzZ2dnim2++Ec7OzsLQ0FBUqlRJ40ayUaNGCWtra2Fqaiq6desmZs2alescRO8SnwhDREQkYfXq1ejTpw9SUlJkG1dLJDd2TxMREb1mxYoVqFq1KsqXL4/z589jzJgx6Nq1KxNG0mtMGomIiF6TkJCACRMmICEhAY6Ojvj44481ntZCpI/YPU1EREREknhrIBERERFJYtJIRERERJKYNBIRERGRJCaNRERERCSJSSMRERERSWLSSERFJiQkBJ06dVK/btWqFb788st3HseBAwegUCiQnJyss3O8/rMWxruIk4ioqDBpJCrhQkJCoFAooFAoYGRkBBcXF0yaNAkvXrzQ+bl///13TJ48uUD7vusEqnLlypg9e/Y7ORcRUUnAyb2J9EC7du2wdOlSZGRkYPv27Rg8eDAMDQ0RFhaWa9/MzEwYGRkVyXnLlStXJO0QEZH8WGkk0gNKpRIODg5wdnbG559/Dj8/P/zxxx8A/tfNOmXKFDg5OcHNzQ0A8Pfff6Nr166wtLREuXLl0LFjR9y5c0fdZnZ2NkJDQ2FpaQlra2uMHj0arz8r4PXu6YyMDIwZMwYVK1aEUqmEi4sLfvnlF9y5cwetW7cGAFhZWUGhUCAkJAQAoFKpEBkZiSpVqsDExAReXl7YsGGDxnm2b9+O6tWrw8TEBK1bt9aIszCys7PRr18/9Tnd3Nzwww8/5LlvREQEbG1tYW5ujs8++wyZmZnqbQWJnYjov4KVRiI9ZGJigsTERPXrvXv3wtzcHLt37wYAZGVlwd/fH02aNMHhw4dRunRpfPPNN2jXrh0uXLgAIyMjfP/991i2bBmWLFkCd3d3fP/999i0aRPatGmT73l79+6NqKgo/Pjjj/Dy8kJsbCwePXqEihUrYuPGjejSpQuuX78Oc3Nz9TN+IyMjsWrVKixYsACurq44dOgQevXqBVtbW7Rs2RJ///03AgMDMXjwYAwcOBCnT5/GiBEj3ur9UalUqFChAn777TdYW1vj2LFjGDhwIBwdHdG1a1eN983Y2BgHDhzAnTt30KdPH1hbW6sfNycVOxHRf4ogohItODhYdOzYUQghhEqlErt37xZKpVKMHDlSvd3e3l5kZGSoj1m5cqVwc3MTKpVKvS4jI0OYmJiInTt3CiGEcHR0FNOnT1dvz8rKEhUqVFCfSwghWrZsKb744gshhBDXr18XAMTu3bvzjHP//v0CgEhKSlKve/78uShTpow4duyYxr79+vUTQUFBQgghwsLCRM2aNTW2jxkzJldbr3N2dhazZs3Kd/vrBg8eLLp06aJ+HRwcLMqVKyeePn2qXjd//nxhamoqsrOzCxR7Xj8zEVFxxUojkR7YunUrTE1NkZWVBZVKhR49eiA8PFy93cPDQ2Mc4/nz53Hr1i2YmZlptPP8+XPExMQgJSUF8fHxaNSokXpb6dKlUb9+/Vxd1Dmio6NRqlQprSpst27dwrNnz/Dee+9prM/MzESdOnUAAFevXtWIAwCaNGlS4HPkZ968eViyZAni4uKQnp6OzMxMeHt7a+zj5eWFMmXKaJw3LS0Nf//9N9LS0iRjJyL6L2HSSKQHWrdujfnz58PIyAhOTk4oXVrzo1+2bFmN12lpaahXrx5Wr16dqy1bW9tCxZDT3ayNtLQ0AMC2bdtQvnx5jW1KpbJQcRTE2rVrMXLkSHz//fdo0qQJzMzMMGPGDJw4caLAbcgVOxGRrjBpJNIDZcuWhYuLS4H3r1u3LtatWwc7OzuYm5vnuY+joyNOnDiBFi1aAABevHiBM2fOoG7dunnu7+HhAZVKhYMHD8LPzy/X9pxKZ3Z2tnpdzZo1oVQqERcXl2+F0t3dXX1TT47jx49L/5BvcPToUTRt2hSDBg1Sr4uJicm13/nz55Genq5OiI8fPw5TU1NUrFgR5cqVk4ydiOi/hHdPE1EuPXv2hI2NDTp27IjDhw8jNjYWBw4cwLBhw3Dv3j0AwBdffIGpU6di8+bNuHbtGgYNGvTGORYrV66M4OBg9O3bF5s3b1a3uX79egCAs7MzFAoFtm7diocPHyItLQ1mZmYYOXIkhg8fjuXLlyMmJgZnz57FnDlzsHz5cgDAZ599hps3b2LUqFG4fv061qxZg2XLlhXo5/znn38QHR2tsSQlJcHV1RWnT5/Gzp07cePGDYwfPx6nTp3KdXxmZib69euHK1euYPv27Zg4cSKGDBkCAwODAsVORPSfIvegSiLSrVdvhNFme3x8vOjdu7ewsbERSqVSVK1aVQwYMECkpKQIIV7e+PLFF18Ic3NzYWlpKUJDQ0Xv3r3zvRFGCCHS09PF8OHDhaOjozAyMhIuLi5iyZIl6u2TJk0SDg4OQqFQiODgYCHEy5t3Zs+eLdzc3IShoaGwtbUV/v7+4uDBg+rj/vzzT+Hi4iKUSqVo3ry5WLJkSYFuhAGQa1m5cqV4/vy5CAkJERYWFsLS0lJ8/vnnYuzYscLLyyvX+zZhwgRhbW0tTE1NxYABA8Tz58/V+0jFzhthiOi/RCFEPqPWiYiIiIj+H7uniYiIiEgSk0YiIiIiksSkkYiIiIgkMWkkIiIiIklMGomIiIhIEpNGIiIiIpLEpJGIiIiIJDFpJCIiIiJJTBqJiIiISBKTRiIiIiKSxKSRiIiIiCT9H28coykQhplHAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}